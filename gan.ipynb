{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# data libraries\n",
    "###########################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###########################\n",
    "# plot libraries\n",
    "###########################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "\n",
    "###########################\n",
    "# data generation\n",
    "###########################\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['domestic' 'industrial' 'rural commercial' 'construction'\n",
      " 'low income families' 'rural domestic' 'rural expansion']\n",
      "[1 2 4 0 3 5 6]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4060/4035412387.py:11: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['Year', 'Month','Consumption' ,'Consumer_number', 'Installation_zone']]= enc.transform(X[['Year', 'Month','Consumption','Consumer_number', 'Installation_zone']])\n",
      "/tmp/ipykernel_4060/4035412387.py:13: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[['Consumer_type']] = enc_label.fit_transform(y[['Consumer_type']])\n",
      "/usr/local/lib/python3.8/dist-packages/sklearn/preprocessing/_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Read data\n",
    "train = pd.read_csv(\"train.csv\")\n",
    "y = train[['Consumer_type']]\n",
    "X = train[['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone']]\n",
    "\n",
    "## Encode data\n",
    "enc = OrdinalEncoder(dtype=np.int16)\n",
    "enc.fit(X)\n",
    "\n",
    "enc_label = OrdinalEncoder(dtype=np.int16)\n",
    "X[['Year', 'Month','Consumption' ,'Consumer_number', 'Installation_zone']]= enc.transform(X[['Year', 'Month','Consumption','Consumer_number', 'Installation_zone']])\n",
    "print(y['Consumer_type'].unique())\n",
    "y[['Consumer_type']] = enc_label.fit_transform(y[['Consumer_type']])\n",
    "print(y.Consumer_type.unique())\n",
    "y = y.Consumer_type\n",
    "\n",
    "test = X\n",
    "\n",
    "\n",
    "test = X\n",
    "## Scale data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## Create data and label\n",
    "data = pd.DataFrame(X, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "label = y.values\n",
    "\n",
    "# One hot encode labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_labels = one_hot_encoder.fit_transform(np.array(label).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4, 5, 6], dtype=int16)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.Year.unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 7\n",
    "NUM_FEATURES = 5\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_STEPS = 500\n",
    "\n",
    "# Generator\n",
    "def create_generator():\n",
    "    noise_input = Input(shape=(NOISE_DIM,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    merged_input = Concatenate()([noise_input, class_input])\n",
    "    hidden = Dense(128, activation='relu')(merged_input)\n",
    "    output = Dense(NUM_FEATURES, activation='linear')(hidden)\n",
    "    model = Model(inputs=[noise_input, class_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def create_discriminator():\n",
    "    data_input = Input(shape=(NUM_FEATURES,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    merged_input = Concatenate()([data_input, class_input])\n",
    "    hidden = Dense(128, activation='relu')(merged_input)\n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    model = Model(inputs=[data_input, class_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# cGAN\n",
    "def create_cgan(generator, discriminator):\n",
    "    noise_input = Input(shape=(NOISE_DIM,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    generated_data = generator([noise_input, class_input])\n",
    "    validity = discriminator([generated_data, class_input])\n",
    "    model = Model(inputs=[noise_input, class_input], outputs=validity)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the Discriminator\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "# Create the Generator\n",
    "generator = create_generator()\n",
    "\n",
    "# Create the GAN\n",
    "gan = create_cgan(generator, discriminator)\n",
    "\n",
    "# Ensure that only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 0, Discriminator Loss: 0.7524538636207581, Generator Loss: 0.5068985223770142\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 2, Discriminator Loss: 0.7327969372272491, Generator Loss: 0.5002732276916504\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 4, Discriminator Loss: 0.7024102807044983, Generator Loss: 0.5364589691162109\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 6, Discriminator Loss: 0.6913334280252457, Generator Loss: 0.5414149761199951\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 8, Discriminator Loss: 0.6519756019115448, Generator Loss: 0.5895926356315613\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 10, Discriminator Loss: 0.6470052599906921, Generator Loss: 0.5890511274337769\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 12, Discriminator Loss: 0.6264240890741348, Generator Loss: 0.6176304817199707\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 14, Discriminator Loss: 0.6456655263900757, Generator Loss: 0.5868374109268188\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 16, Discriminator Loss: 0.579439640045166, Generator Loss: 0.6742035150527954\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 18, Discriminator Loss: 0.5881357938051224, Generator Loss: 0.6738584041595459\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 20, Discriminator Loss: 0.5520062148571014, Generator Loss: 0.7594277858734131\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 22, Discriminator Loss: 0.5705546140670776, Generator Loss: 0.7303571105003357\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 24, Discriminator Loss: 0.6107712686061859, Generator Loss: 0.7083795070648193\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 26, Discriminator Loss: 0.5413166880607605, Generator Loss: 0.8158769607543945\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 28, Discriminator Loss: 0.601173922419548, Generator Loss: 0.7183990478515625\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 30, Discriminator Loss: 0.6434755176305771, Generator Loss: 0.7019652128219604\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 32, Discriminator Loss: 0.6123587489128113, Generator Loss: 0.732538104057312\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 34, Discriminator Loss: 0.6649660468101501, Generator Loss: 0.6253859996795654\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 36, Discriminator Loss: 0.7274302989244461, Generator Loss: 0.5786023736000061\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 38, Discriminator Loss: 0.6981712877750397, Generator Loss: 0.5945391654968262\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 40, Discriminator Loss: 0.7557549178600311, Generator Loss: 0.5986672043800354\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 42, Discriminator Loss: 0.8301089406013489, Generator Loss: 0.5217130184173584\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 44, Discriminator Loss: 0.7952731251716614, Generator Loss: 0.5212377309799194\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 46, Discriminator Loss: 0.7597320675849915, Generator Loss: 0.593502402305603\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 48, Discriminator Loss: 0.7550133168697357, Generator Loss: 0.6455368995666504\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 50, Discriminator Loss: 0.7502003610134125, Generator Loss: 0.6266055107116699\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 52, Discriminator Loss: 0.7082403302192688, Generator Loss: 0.7539176940917969\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 54, Discriminator Loss: 0.6962214708328247, Generator Loss: 0.7906665802001953\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 56, Discriminator Loss: 0.6740704774856567, Generator Loss: 0.8925806283950806\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 58, Discriminator Loss: 0.6703415215015411, Generator Loss: 0.9458407163619995\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 60, Discriminator Loss: 0.6058382391929626, Generator Loss: 1.1634843349456787\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 62, Discriminator Loss: 0.5919182002544403, Generator Loss: 1.2330260276794434\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 64, Discriminator Loss: 0.5780843645334244, Generator Loss: 1.3725924491882324\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 66, Discriminator Loss: 0.6002180874347687, Generator Loss: 1.3734734058380127\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 68, Discriminator Loss: 0.588739424943924, Generator Loss: 1.3500953912734985\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 70, Discriminator Loss: 0.5788766741752625, Generator Loss: 1.5099965333938599\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 72, Discriminator Loss: 0.5508566647768021, Generator Loss: 1.4912474155426025\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 74, Discriminator Loss: 0.577748566865921, Generator Loss: 1.3710085153579712\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 76, Discriminator Loss: 0.5383857786655426, Generator Loss: 1.5477374792099\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 78, Discriminator Loss: 0.5551891028881073, Generator Loss: 1.448563814163208\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 80, Discriminator Loss: 0.533228725194931, Generator Loss: 1.4849450588226318\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 82, Discriminator Loss: 0.5255614519119263, Generator Loss: 1.5064234733581543\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 84, Discriminator Loss: 0.5373587906360626, Generator Loss: 1.3811447620391846\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 86, Discriminator Loss: 0.5285423696041107, Generator Loss: 1.407617449760437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 88, Discriminator Loss: 0.5365908145904541, Generator Loss: 1.338691234588623\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 90, Discriminator Loss: 0.5079503059387207, Generator Loss: 1.4026297330856323\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 92, Discriminator Loss: 0.5375356376171112, Generator Loss: 1.2485805749893188\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 94, Discriminator Loss: 0.5290228575468063, Generator Loss: 1.2670050859451294\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 96, Discriminator Loss: 0.5294849425554276, Generator Loss: 1.250603437423706\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 98, Discriminator Loss: 0.5143481492996216, Generator Loss: 1.2587002515792847\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 100, Discriminator Loss: 0.5366142094135284, Generator Loss: 1.2488083839416504\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 102, Discriminator Loss: 0.49987317621707916, Generator Loss: 1.282778024673462\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 104, Discriminator Loss: 0.5119220167398453, Generator Loss: 1.2353358268737793\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 106, Discriminator Loss: 0.5164077430963516, Generator Loss: 1.2310696840286255\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 108, Discriminator Loss: 0.5047851502895355, Generator Loss: 1.2537243366241455\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 110, Discriminator Loss: 0.48818325996398926, Generator Loss: 1.296404242515564\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 112, Discriminator Loss: 0.516045093536377, Generator Loss: 1.210556983947754\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 114, Discriminator Loss: 0.522006943821907, Generator Loss: 1.2340022325515747\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 116, Discriminator Loss: 0.48767833411693573, Generator Loss: 1.346117377281189\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 118, Discriminator Loss: 0.5022176653146744, Generator Loss: 1.2583224773406982\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 120, Discriminator Loss: 0.4927438795566559, Generator Loss: 1.21034836769104\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 122, Discriminator Loss: 0.5047954320907593, Generator Loss: 1.1128895282745361\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 124, Discriminator Loss: 0.5115405768156052, Generator Loss: 1.1487345695495605\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 126, Discriminator Loss: 0.4975510835647583, Generator Loss: 1.1997928619384766\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 128, Discriminator Loss: 0.5164043456315994, Generator Loss: 1.0919486284255981\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 130, Discriminator Loss: 0.5211097598075867, Generator Loss: 1.0720068216323853\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 132, Discriminator Loss: 0.537398487329483, Generator Loss: 1.035017490386963\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 134, Discriminator Loss: 0.5465074479579926, Generator Loss: 0.9859901666641235\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 136, Discriminator Loss: 0.561614602804184, Generator Loss: 0.9423066973686218\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 138, Discriminator Loss: 0.5543704628944397, Generator Loss: 0.9367979168891907\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 140, Discriminator Loss: 0.5787256360054016, Generator Loss: 0.8794016242027283\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 142, Discriminator Loss: 0.5709044933319092, Generator Loss: 0.9109310507774353\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 144, Discriminator Loss: 0.5740278363227844, Generator Loss: 0.910518229007721\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 146, Discriminator Loss: 0.5635298192501068, Generator Loss: 0.9334089159965515\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 148, Discriminator Loss: 0.574620932340622, Generator Loss: 0.8862011432647705\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 150, Discriminator Loss: 0.5790847837924957, Generator Loss: 0.9214537143707275\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 152, Discriminator Loss: 0.5620526075363159, Generator Loss: 0.9570324420928955\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 154, Discriminator Loss: 0.5524396598339081, Generator Loss: 0.9610021114349365\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 156, Discriminator Loss: 0.5649216771125793, Generator Loss: 0.9330085515975952\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 158, Discriminator Loss: 0.5842748582363129, Generator Loss: 0.8911082148551941\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 160, Discriminator Loss: 0.5840493738651276, Generator Loss: 0.8871987462043762\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 162, Discriminator Loss: 0.605403482913971, Generator Loss: 0.8410115242004395\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 164, Discriminator Loss: 0.6177256405353546, Generator Loss: 0.8058512806892395\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 166, Discriminator Loss: 0.6332504749298096, Generator Loss: 0.7736730575561523\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 168, Discriminator Loss: 0.6379511058330536, Generator Loss: 0.7388805150985718\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 170, Discriminator Loss: 0.6486184298992157, Generator Loss: 0.7126002311706543\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 172, Discriminator Loss: 0.6405125260353088, Generator Loss: 0.706879198551178\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 174, Discriminator Loss: 0.6649625599384308, Generator Loss: 0.6835488080978394\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 176, Discriminator Loss: 0.6767769455909729, Generator Loss: 0.6648879051208496\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 178, Discriminator Loss: 0.6676579415798187, Generator Loss: 0.6795326471328735\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 180, Discriminator Loss: 0.6406614780426025, Generator Loss: 0.7034857869148254\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 182, Discriminator Loss: 0.6466907560825348, Generator Loss: 0.7011334896087646\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 184, Discriminator Loss: 0.6264774799346924, Generator Loss: 0.7348624467849731\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 186, Discriminator Loss: 0.6202840507030487, Generator Loss: 0.7528051137924194\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 188, Discriminator Loss: 0.6087543070316315, Generator Loss: 0.7645853757858276\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 190, Discriminator Loss: 0.60810586810112, Generator Loss: 0.7700485587120056\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 192, Discriminator Loss: 0.6080340147018433, Generator Loss: 0.7806941866874695\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 194, Discriminator Loss: 0.6119515597820282, Generator Loss: 0.7674387693405151\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 196, Discriminator Loss: 0.6110532283782959, Generator Loss: 0.7531836628913879\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 198, Discriminator Loss: 0.6218549013137817, Generator Loss: 0.7400221824645996\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 200, Discriminator Loss: 0.6257719695568085, Generator Loss: 0.7258196473121643\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 202, Discriminator Loss: 0.64284947514534, Generator Loss: 0.6881611347198486\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 204, Discriminator Loss: 0.6374413371086121, Generator Loss: 0.6943236589431763\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 206, Discriminator Loss: 0.6590107679367065, Generator Loss: 0.6637526154518127\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 208, Discriminator Loss: 0.6550030708312988, Generator Loss: 0.6576386094093323\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 210, Discriminator Loss: 0.6529189050197601, Generator Loss: 0.6569722890853882\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 212, Discriminator Loss: 0.6874973773956299, Generator Loss: 0.623809814453125\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 214, Discriminator Loss: 0.6831328570842743, Generator Loss: 0.624524712562561\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 216, Discriminator Loss: 0.6889531314373016, Generator Loss: 0.6236487030982971\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 218, Discriminator Loss: 0.6877234280109406, Generator Loss: 0.6453608274459839\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 220, Discriminator Loss: 0.6722426414489746, Generator Loss: 0.6624454259872437\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 222, Discriminator Loss: 0.6882978677749634, Generator Loss: 0.6543995141983032\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 224, Discriminator Loss: 0.6825959086418152, Generator Loss: 0.6686549186706543\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 226, Discriminator Loss: 0.6585437953472137, Generator Loss: 0.7113348841667175\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 228, Discriminator Loss: 0.6713651418685913, Generator Loss: 0.710742712020874\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 230, Discriminator Loss: 0.6532943248748779, Generator Loss: 0.7515432834625244\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 232, Discriminator Loss: 0.6499203443527222, Generator Loss: 0.7548424005508423\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 234, Discriminator Loss: 0.6544890105724335, Generator Loss: 0.7590749263763428\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 236, Discriminator Loss: 0.6594218015670776, Generator Loss: 0.7648435235023499\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 238, Discriminator Loss: 0.6603949069976807, Generator Loss: 0.7568775415420532\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 240, Discriminator Loss: 0.6642352938652039, Generator Loss: 0.7430229187011719\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 242, Discriminator Loss: 0.6601382791996002, Generator Loss: 0.7669092416763306\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 244, Discriminator Loss: 0.6656373143196106, Generator Loss: 0.7537000179290771\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 246, Discriminator Loss: 0.6772610247135162, Generator Loss: 0.735907793045044\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 248, Discriminator Loss: 0.6760097444057465, Generator Loss: 0.7217155694961548\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 250, Discriminator Loss: 0.6765498518943787, Generator Loss: 0.7162718176841736\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 252, Discriminator Loss: 0.6784188151359558, Generator Loss: 0.7161986231803894\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 254, Discriminator Loss: 0.6790134310722351, Generator Loss: 0.7088332772254944\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 256, Discriminator Loss: 0.6907304525375366, Generator Loss: 0.7105008363723755\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 258, Discriminator Loss: 0.6848799884319305, Generator Loss: 0.7011767625808716\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 260, Discriminator Loss: 0.674544483423233, Generator Loss: 0.7115457057952881\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 262, Discriminator Loss: 0.6814714074134827, Generator Loss: 0.7042311429977417\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 264, Discriminator Loss: 0.6689306199550629, Generator Loss: 0.717793345451355\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 266, Discriminator Loss: 0.6780730485916138, Generator Loss: 0.6940675973892212\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 268, Discriminator Loss: 0.6752774119377136, Generator Loss: 0.7046170234680176\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 270, Discriminator Loss: 0.6759277880191803, Generator Loss: 0.6936491131782532\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 272, Discriminator Loss: 0.67146235704422, Generator Loss: 0.6912878751754761\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 274, Discriminator Loss: 0.6682409346103668, Generator Loss: 0.7091308832168579\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 276, Discriminator Loss: 0.6825768351554871, Generator Loss: 0.6772570610046387\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 278, Discriminator Loss: 0.6711452603340149, Generator Loss: 0.7102829217910767\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 280, Discriminator Loss: 0.6857859492301941, Generator Loss: 0.6706793308258057\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 282, Discriminator Loss: 0.6839894950389862, Generator Loss: 0.6703118681907654\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 284, Discriminator Loss: 0.6770246028900146, Generator Loss: 0.6858375668525696\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 286, Discriminator Loss: 0.6935884952545166, Generator Loss: 0.6579521894454956\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 288, Discriminator Loss: 0.6693179905414581, Generator Loss: 0.7083594799041748\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 290, Discriminator Loss: 0.6798544526100159, Generator Loss: 0.6965241432189941\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 292, Discriminator Loss: 0.6774393916130066, Generator Loss: 0.691520094871521\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 294, Discriminator Loss: 0.6861082315444946, Generator Loss: 0.6924252510070801\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 296, Discriminator Loss: 0.6815922856330872, Generator Loss: 0.7008688449859619\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 298, Discriminator Loss: 0.680990606546402, Generator Loss: 0.6973614692687988\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 300, Discriminator Loss: 0.6886248886585236, Generator Loss: 0.6874352693557739\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 302, Discriminator Loss: 0.6829830408096313, Generator Loss: 0.7069356441497803\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 304, Discriminator Loss: 0.6774910390377045, Generator Loss: 0.7082899212837219\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 306, Discriminator Loss: 0.6971689462661743, Generator Loss: 0.685065507888794\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 308, Discriminator Loss: 0.6855316758155823, Generator Loss: 0.7091070413589478\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 310, Discriminator Loss: 0.6877557337284088, Generator Loss: 0.7066280841827393\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 312, Discriminator Loss: 0.6849570572376251, Generator Loss: 0.7049518823623657\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 314, Discriminator Loss: 0.6816461980342865, Generator Loss: 0.7098017930984497\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 316, Discriminator Loss: 0.6849527657032013, Generator Loss: 0.7102502584457397\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 318, Discriminator Loss: 0.6893723011016846, Generator Loss: 0.6986314058303833\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 320, Discriminator Loss: 0.6795792877674103, Generator Loss: 0.7356503009796143\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 322, Discriminator Loss: 0.6869279146194458, Generator Loss: 0.711580753326416\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 324, Discriminator Loss: 0.6841294765472412, Generator Loss: 0.699722409248352\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 326, Discriminator Loss: 0.6900960803031921, Generator Loss: 0.7128274440765381\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 328, Discriminator Loss: 0.6800609230995178, Generator Loss: 0.7165310382843018\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 330, Discriminator Loss: 0.6793054938316345, Generator Loss: 0.7146693468093872\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 332, Discriminator Loss: 0.6807558536529541, Generator Loss: 0.7060148119926453\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 334, Discriminator Loss: 0.6808276474475861, Generator Loss: 0.7081262469291687\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 336, Discriminator Loss: 0.6841817200183868, Generator Loss: 0.7136858701705933\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 338, Discriminator Loss: 0.6778308153152466, Generator Loss: 0.7163970470428467\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 340, Discriminator Loss: 0.7022550106048584, Generator Loss: 0.6735976338386536\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 342, Discriminator Loss: 0.693827360868454, Generator Loss: 0.6895856857299805\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 344, Discriminator Loss: 0.6871278285980225, Generator Loss: 0.6972329020500183\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 346, Discriminator Loss: 0.6860184967517853, Generator Loss: 0.6866546273231506\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 348, Discriminator Loss: 0.6831501722335815, Generator Loss: 0.6981602907180786\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 350, Discriminator Loss: 0.6750420928001404, Generator Loss: 0.713862419128418\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 352, Discriminator Loss: 0.6877598762512207, Generator Loss: 0.68946772813797\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 354, Discriminator Loss: 0.690619170665741, Generator Loss: 0.6874933242797852\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 356, Discriminator Loss: 0.688323974609375, Generator Loss: 0.6980118751525879\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 358, Discriminator Loss: 0.6865836381912231, Generator Loss: 0.6923509836196899\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 360, Discriminator Loss: 0.6781618297100067, Generator Loss: 0.7061622142791748\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 362, Discriminator Loss: 0.680846095085144, Generator Loss: 0.6978099942207336\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 364, Discriminator Loss: 0.6833173930644989, Generator Loss: 0.7082616090774536\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 366, Discriminator Loss: 0.6826268434524536, Generator Loss: 0.6924662590026855\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 368, Discriminator Loss: 0.6864095628261566, Generator Loss: 0.6917044520378113\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 370, Discriminator Loss: 0.6757282316684723, Generator Loss: 0.7248866558074951\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 372, Discriminator Loss: 0.6854448914527893, Generator Loss: 0.6901459693908691\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 374, Discriminator Loss: 0.677322119474411, Generator Loss: 0.7147216200828552\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 376, Discriminator Loss: 0.6773429811000824, Generator Loss: 0.7102832198143005\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 378, Discriminator Loss: 0.6766060590744019, Generator Loss: 0.725234866142273\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 380, Discriminator Loss: 0.690243273973465, Generator Loss: 0.6923443078994751\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 382, Discriminator Loss: 0.6897887587547302, Generator Loss: 0.6948968172073364\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 384, Discriminator Loss: 0.6837518215179443, Generator Loss: 0.7018373608589172\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 386, Discriminator Loss: 0.6864494383335114, Generator Loss: 0.7048661112785339\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 388, Discriminator Loss: 0.6919272243976593, Generator Loss: 0.6907088756561279\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 390, Discriminator Loss: 0.6850263774394989, Generator Loss: 0.7016217708587646\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 392, Discriminator Loss: 0.6867268979549408, Generator Loss: 0.6947345733642578\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 394, Discriminator Loss: 0.6833502352237701, Generator Loss: 0.7090452313423157\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 396, Discriminator Loss: 0.6916860044002533, Generator Loss: 0.6920799016952515\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 398, Discriminator Loss: 0.6848554611206055, Generator Loss: 0.7052739858627319\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 400, Discriminator Loss: 0.6810825169086456, Generator Loss: 0.7100933790206909\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 402, Discriminator Loss: 0.6979928314685822, Generator Loss: 0.6904981136322021\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 404, Discriminator Loss: 0.6846829056739807, Generator Loss: 0.7022439241409302\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 406, Discriminator Loss: 0.6899514198303223, Generator Loss: 0.7157482504844666\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 408, Discriminator Loss: 0.6908003389835358, Generator Loss: 0.6936550140380859\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 410, Discriminator Loss: 0.6933543086051941, Generator Loss: 0.6938461065292358\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 412, Discriminator Loss: 0.6943123936653137, Generator Loss: 0.6928712129592896\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 414, Discriminator Loss: 0.693463146686554, Generator Loss: 0.6784999370574951\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 416, Discriminator Loss: 0.6964644193649292, Generator Loss: 0.689739465713501\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 418, Discriminator Loss: 0.6984899938106537, Generator Loss: 0.6760414838790894\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 420, Discriminator Loss: 0.6915631294250488, Generator Loss: 0.6934176683425903\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 422, Discriminator Loss: 0.6937696933746338, Generator Loss: 0.6912059187889099\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 424, Discriminator Loss: 0.6864270865917206, Generator Loss: 0.6968533992767334\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 426, Discriminator Loss: 0.6825122833251953, Generator Loss: 0.7107681632041931\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 428, Discriminator Loss: 0.6875809729099274, Generator Loss: 0.7037767171859741\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 430, Discriminator Loss: 0.6849138736724854, Generator Loss: 0.6986677646636963\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 432, Discriminator Loss: 0.6922299861907959, Generator Loss: 0.7006646394729614\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 434, Discriminator Loss: 0.6882404685020447, Generator Loss: 0.6898695826530457\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 436, Discriminator Loss: 0.6942970156669617, Generator Loss: 0.6955066323280334\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 438, Discriminator Loss: 0.7005804479122162, Generator Loss: 0.6736173629760742\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 440, Discriminator Loss: 0.6949815154075623, Generator Loss: 0.6944156885147095\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 442, Discriminator Loss: 0.6956945359706879, Generator Loss: 0.6898578405380249\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 444, Discriminator Loss: 0.6925154626369476, Generator Loss: 0.6938322186470032\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 446, Discriminator Loss: 0.6890698075294495, Generator Loss: 0.7039943337440491\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 448, Discriminator Loss: 0.6876572370529175, Generator Loss: 0.7038407921791077\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 450, Discriminator Loss: 0.6881625056266785, Generator Loss: 0.6955406665802002\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 452, Discriminator Loss: 0.6851547658443451, Generator Loss: 0.7106766700744629\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 454, Discriminator Loss: 0.6882472634315491, Generator Loss: 0.697750985622406\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 456, Discriminator Loss: 0.7009950280189514, Generator Loss: 0.691132664680481\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 458, Discriminator Loss: 0.6899872124195099, Generator Loss: 0.69825279712677\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 460, Discriminator Loss: 0.7030234336853027, Generator Loss: 0.6765491366386414\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 462, Discriminator Loss: 0.6906977295875549, Generator Loss: 0.7077005505561829\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 464, Discriminator Loss: 0.6869533658027649, Generator Loss: 0.7098982334136963\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 466, Discriminator Loss: 0.6976258754730225, Generator Loss: 0.6893317699432373\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 468, Discriminator Loss: 0.6977483034133911, Generator Loss: 0.6897832155227661\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 470, Discriminator Loss: 0.6944999992847443, Generator Loss: 0.6923556327819824\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 472, Discriminator Loss: 0.6925663352012634, Generator Loss: 0.693195104598999\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 474, Discriminator Loss: 0.6921122074127197, Generator Loss: 0.706072211265564\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 476, Discriminator Loss: 0.6911326348781586, Generator Loss: 0.6984995603561401\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 478, Discriminator Loss: 0.6816652119159698, Generator Loss: 0.7125598192214966\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 480, Discriminator Loss: 0.6919562816619873, Generator Loss: 0.7014431953430176\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 482, Discriminator Loss: 0.6885205507278442, Generator Loss: 0.7039130926132202\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 484, Discriminator Loss: 0.6876249313354492, Generator Loss: 0.7010337114334106\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 486, Discriminator Loss: 0.6908585429191589, Generator Loss: 0.7113653421401978\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 488, Discriminator Loss: 0.6875, Generator Loss: 0.7053733468055725\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 490, Discriminator Loss: 0.6922375559806824, Generator Loss: 0.6951062083244324\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 492, Discriminator Loss: 0.6925043165683746, Generator Loss: 0.7135956287384033\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 494, Discriminator Loss: 0.6990191638469696, Generator Loss: 0.6927388310432434\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 496, Discriminator Loss: 0.7019623517990112, Generator Loss: 0.678802490234375\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 498, Discriminator Loss: 0.6888288259506226, Generator Loss: 0.7039011716842651\n",
      "2/2 [==============================] - 0s 3ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train GAN\n",
    "dl = []\n",
    "gl = []\n",
    "for step in range(TRAINING_STEPS):\n",
    "    # Select a random batch of real data with labels\n",
    "    idx = np.random.randint(0, data.shape[0], BATCH_SIZE)\n",
    "    real_batch = data.iloc[idx].values\n",
    "    labels_batch = one_hot_labels[idx]\n",
    "\n",
    "    # Generate a batch of new data\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
    "    generated_batch = generator.predict([noise, labels_batch])\n",
    "\n",
    "    # Train the discriminator\n",
    "    real_loss = discriminator.train_on_batch([real_batch, labels_batch], np.ones((BATCH_SIZE, 1)))\n",
    "    fake_loss = discriminator.train_on_batch([generated_batch, labels_batch], np.zeros((BATCH_SIZE, 1)))\n",
    "    discriminator_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "\n",
    "    # Train the generator\n",
    "    generator_loss = gan.train_on_batch([noise, labels_batch], np.ones((BATCH_SIZE, 1)))\n",
    "    dl.append(discriminator_loss)\n",
    "    gl.append(generator_loss)\n",
    "    if step % 2 == 0:\n",
    "        print(f\"Step: {step}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x7f754fccbca0>"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(dl, label='discriminator loss', color='blue', linestyle='-')\n",
    "plt.plot(gl, label='generator loss', color='red', linestyle='-')\n",
    "\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(generator, data_class, num_instances):\n",
    "    one_hot_class = one_hot_encoder.transform(np.array([[data_class]]))\n",
    "    noise = np.random.normal(0, 1, (num_instances, NOISE_DIM))\n",
    "    generated_data = generator.predict([noise, np.repeat(one_hot_class, num_instances, axis=0)])\n",
    "    return pd.DataFrame(generated_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 3ms/step\n",
      "        Year     Month  Consumption  Consumer_number  Installation_zone\n",
      "0   0.714042  0.216750     0.078668         0.365696           0.610488\n",
      "1   0.647615  0.429212     0.015256         0.708676           0.660444\n",
      "2   0.797087  0.797765     0.094022         1.001881           0.628598\n",
      "3   0.435841  0.354080     0.083072         0.074430           0.384383\n",
      "4   0.526893  0.240782     0.119614         0.402331           0.459051\n",
      "5   0.735353  0.397003    -0.055848         0.609335           0.176069\n",
      "6   0.345009  0.593901     0.051569         0.338708           0.322092\n",
      "7   0.529837  0.257777    -0.137855         0.057990           0.314130\n",
      "8   0.435255  0.595488     0.185457         0.482714           0.134296\n",
      "9   0.955233  0.571221     0.054691         0.544749           0.360056\n",
      "10  0.566216  0.744195     0.120530         0.477023           0.322315\n",
      "11  0.533047  0.549443     0.189889         0.570446           0.626547\n",
      "12  0.568205  0.937561     0.074618         0.335350           0.863738\n",
      "13  0.610450  0.358637     0.028032         0.752920           0.382226\n",
      "14  0.395414  0.114924     0.279522         0.336804           0.313012\n",
      "15  0.574233  0.441353     0.119436         0.549384          -0.021545\n",
      "16  0.239488  0.377369     0.029599         0.636110           0.194904\n",
      "17  0.636846  0.151786     0.072181         0.679686           0.143680\n",
      "18  0.242158 -0.012612    -0.140653         0.045964           0.337159\n",
      "19  0.584034  0.435767    -0.004769         0.600787           0.175563\n",
      "20  0.737514  0.591535    -0.122628         0.394186           0.202628\n",
      "21  0.324802  0.322291     0.260061         0.306355           0.407304\n",
      "22  0.489810  0.468004    -0.239913         0.521498           0.112244\n",
      "23  0.553742  0.228572     0.071137         0.098085           0.417383\n",
      "24  0.489345  0.426258     0.031509         0.195612           0.344483\n",
      "25  0.501198  0.428300    -0.070375         0.722649          -0.066490\n",
      "26  0.640426  0.126610     0.211767         0.778797           0.312570\n",
      "27  0.695374  0.464278     0.110744         0.505987           0.513474\n",
      "28  0.451132  0.114867     0.090467         0.293600           0.401919\n",
      "29  0.165331  0.612321     0.232151         0.701756           0.377536\n",
      "30  0.451722  0.141866     0.381341         0.030539           0.577083\n",
      "31  0.743461  0.569611     0.159247         0.570751           0.416545\n",
      "32  0.505020  0.392611     0.136413         0.335617           0.351484\n",
      "33  0.535079  0.423808    -0.266090         0.187407          -0.076091\n",
      "34  0.285671  0.517841    -0.115576         0.351521           0.305539\n",
      "35  0.530377  0.436735    -0.040149         0.527893           0.586832\n",
      "36  0.522581  0.335265     0.214603         0.448263           0.327685\n",
      "37  0.679780  0.222969    -0.099532         0.262874           0.072604\n",
      "38  0.296712  0.148011     0.041924         0.506105           0.662114\n",
      "39  0.740261  0.439413     0.173263         0.479915           0.148890\n"
     ]
    }
   ],
   "source": [
    "generated_data = generate_data(generator, 1, 40)\n",
    "print(generated_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 10s 2ms/step\n",
      "   Year Month Consumer_type Consumption     Consumer_number  \\\n",
      "0  2016     5  construction           0  HXTW27159220813061   \n",
      "1  2017     4  construction           0  KACY51026398172973   \n",
      "2  2019     5  construction          35  DBRZ37213883240498   \n",
      "3  2020     6  construction          68  NSNL75855216706785   \n",
      "4  2017     4  construction           0  OCOJ78634676240808   \n",
      "\n",
      "      Installation_zone  \n",
      "0  Installation_zone 31  \n",
      "1  Installation_zone 39  \n",
      "2  Installation_zone 33  \n",
      "3  Installation_zone 46  \n",
      "4  Installation_zone 43  \n",
      "5625/5625 [==============================] - 9s 2ms/step\n",
      "6344/6344 [==============================] - 10s 2ms/step\n",
      "6250/6250 [==============================] - 10s 2ms/step\n",
      "5000/5000 [==============================] - 8s 2ms/step\n",
      "6344/6344 [==============================] - 10s 2ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate 50 instances for each class\n",
    "# ['domestic' 'industrial' 'rural commercial' 'construction'\n",
    "#  'low income families' 'rural domestic' 'rural expansion']\n",
    "# [1 2 4 0 3 5 6]\n",
    "\n",
    "synthetic_data_class_0 = generate_data(generator, 0, 200000)\n",
    "generated_data_clipped = np.clip(synthetic_data_class_0, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(scaler.inverse_transform(generated_data_clipped), columns=['Year', 'Month','Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "NewDataFrame0 = pd.DataFrame(synthetic_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "NewDataFrame0.insert(NewDataFrame0.columns.get_loc('Consumption'), \"Consumer_type\", 'construction')\n",
    "print(NewDataFrame0.head())\n",
    "\n",
    "synthetic_data_class_2 = generate_data(generator, 2, 180000)\n",
    "generated_data_clipped = np.clip(synthetic_data_class_2, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(scaler.inverse_transform(generated_data_clipped), columns=['Year', 'Month','Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "NewDataFrame2 = pd.DataFrame(synthetic_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "NewDataFrame2.insert(NewDataFrame2.columns.get_loc('Consumption'), \"Consumer_type\", 'industrial')\n",
    "\n",
    "synthetic_data_class_3 = generate_data(generator, 3, 203000)\n",
    "generated_data_clipped = np.clip(synthetic_data_class_3, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(scaler.inverse_transform(generated_data_clipped), columns=['Year', 'Month','Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "NewDataFrame3 = pd.DataFrame(synthetic_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "NewDataFrame3.insert(NewDataFrame3.columns.get_loc('Consumption'), \"Consumer_type\", 'low income families')\n",
    "\n",
    "synthetic_data_class_4 = generate_data(generator, 4, 200000)\n",
    "generated_data_clipped = np.clip(synthetic_data_class_4, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(scaler.inverse_transform(generated_data_clipped), columns=['Year', 'Month','Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "NewDataFrame4 = pd.DataFrame(synthetic_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "NewDataFrame4.insert(NewDataFrame4.columns.get_loc('Consumption'), \"Consumer_type\", 'rural commercial')\n",
    "\n",
    "synthetic_data_class_5 = generate_data(generator, 5, 160000)\n",
    "generated_data_clipped = np.clip(synthetic_data_class_5, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(scaler.inverse_transform(generated_data_clipped), columns=['Year', 'Month','Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "NewDataFrame5 = pd.DataFrame(synthetic_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "NewDataFrame5.insert(NewDataFrame5.columns.get_loc('Consumption'), \"Consumer_type\", 'rural domestic')\n",
    "\n",
    "synthetic_data_class_6 = generate_data(generator, 6, 203000)\n",
    "generated_data_clipped = np.clip(synthetic_data_class_6, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(scaler.inverse_transform(generated_data_clipped), columns=['Year', 'Month','Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "NewDataFrame6 = pd.DataFrame(synthetic_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "NewDataFrame6.insert(NewDataFrame6.columns.get_loc('Consumption'), \"Consumer_type\", 'rural expansion')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Year Month Consumer_type Consumption     Consumer_number  \\\n",
      "0  2016     5  construction           0  HXTW27159220813061   \n",
      "1  2017     4  construction           0  KACY51026398172973   \n",
      "2  2019     5  construction          35  DBRZ37213883240498   \n",
      "3  2020     6  construction          68  NSNL75855216706785   \n",
      "4  2017     4  construction           0  OCOJ78634676240808   \n",
      "\n",
      "      Installation_zone  \n",
      "0  Installation_zone 31  \n",
      "1  Installation_zone 39  \n",
      "2  Installation_zone 33  \n",
      "3  Installation_zone 46  \n",
      "4  Installation_zone 43  \n"
     ]
    }
   ],
   "source": [
    "NewData = pd.concat([NewDataFrame0, NewDataFrame2, NewDataFrame3,NewDataFrame4,NewDataFrame5,NewDataFrame6], ignore_index=True)\n",
    "print(NewData.head())\n",
    "NewData.to_csv('teste.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
