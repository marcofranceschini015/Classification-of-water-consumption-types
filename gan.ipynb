{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "###########################\n",
    "# data libraries\n",
    "###########################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###########################\n",
    "# plot libraries\n",
    "###########################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "###########################\n",
    "# data generation\n",
    "###########################\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) READ DATA AND ENCODE/SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_26604\\3114364111.py:14: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  X[['Year', 'Month','Consumption' ,'Consumer_number', 'Installation_zone']]= enc.transform(X[['Year', 'Month','Consumption','Consumer_number', 'Installation_zone']])\n",
      "C:\\Users\\marco\\AppData\\Local\\Temp\\ipykernel_26604\\3114364111.py:15: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  y[['Consumer_type']] = enc_label.fit_transform(y[['Consumer_type']])\n",
      "c:\\Users\\marco\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\preprocessing\\_encoders.py:975: FutureWarning: `sparse` was renamed to `sparse_output` in version 1.2 and will be removed in 1.4. `sparse_output` is ignored unless you leave `sparse` to its default value.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "## Read data\n",
    "train = pd.read_csv(\"train_without_outliers.csv\")\n",
    "\n",
    "train = train[train['Consumer_type'] != 'domestic']\n",
    "y = train[['Consumer_type']]\n",
    "compare_label = y\n",
    "X = train[['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone']]\n",
    "\n",
    "## Encode data\n",
    "enc = OrdinalEncoder(dtype=np.int16)\n",
    "enc.fit(X)\n",
    "\n",
    "enc_label = OrdinalEncoder(dtype=np.int16)\n",
    "X[['Year', 'Month','Consumption' ,'Consumer_number', 'Installation_zone']]= enc.transform(X[['Year', 'Month','Consumption','Consumer_number', 'Installation_zone']])\n",
    "y[['Consumer_type']] = enc_label.fit_transform(y[['Consumer_type']])\n",
    "y = y.Consumer_type\n",
    "\n",
    "## Scale data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## Create data and label\n",
    "data = pd.DataFrame(X, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "label = y.values\n",
    "\n",
    "# One hot encode labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_labels = one_hot_encoder.fit_transform(np.array(label).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) GENERATOR AND DISCRIMINATOR + HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 6\n",
    "NUM_FEATURES = 5\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_STEPS = 1000\n",
    "\n",
    "# Generator\n",
    "def create_generator():\n",
    "    noise_input = Input(shape=(NOISE_DIM,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    merged_input = Concatenate()([noise_input, class_input])\n",
    "    hidden = Dense(128, activation='relu')(merged_input)\n",
    "    output = Dense(NUM_FEATURES, activation='linear')(hidden)\n",
    "    model = Model(inputs=[noise_input, class_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def create_discriminator():\n",
    "    data_input = Input(shape=(NUM_FEATURES,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    merged_input = Concatenate()([data_input, class_input])\n",
    "    hidden = Dense(128, activation='relu')(merged_input)\n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    model = Model(inputs=[data_input, class_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# cGAN\n",
    "def create_cgan(generator, discriminator):\n",
    "    noise_input = Input(shape=(NOISE_DIM,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    generated_data = generator([noise_input, class_input])\n",
    "    validity = discriminator([generated_data, class_input])\n",
    "    model = Model(inputs=[noise_input, class_input], outputs=validity)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the Discriminator\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.0002))\n",
    "\n",
    "# Create the Generator\n",
    "generator = create_generator()\n",
    "\n",
    "# Create the GAN\n",
    "gan = create_cgan(generator, discriminator)\n",
    "\n",
    "# Ensure that only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam(learning_rate=0.005))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) TRAINING OF THE GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 0s 13ms/step\n",
      "Step: 0, Discriminator Loss: 0.7182888388633728, Generator Loss: 0.7367209196090698\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 2, Discriminator Loss: 0.797305166721344, Generator Loss: 0.6033977270126343\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 4, Discriminator Loss: 0.8959114253520966, Generator Loss: 0.4600687623023987\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 6, Discriminator Loss: 0.9766449332237244, Generator Loss: 0.3837985694408417\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 8, Discriminator Loss: 1.0990628004074097, Generator Loss: 0.2880527675151825\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 10, Discriminator Loss: 1.2117479741573334, Generator Loss: 0.2253449708223343\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 12, Discriminator Loss: 1.282833218574524, Generator Loss: 0.19256070256233215\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 14, Discriminator Loss: 1.3227185904979706, Generator Loss: 0.1810382604598999\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 16, Discriminator Loss: 1.3675976991653442, Generator Loss: 0.1627253293991089\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 18, Discriminator Loss: 1.4604756832122803, Generator Loss: 0.13625779747962952\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 20, Discriminator Loss: 1.448923945426941, Generator Loss: 0.13779467344284058\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 22, Discriminator Loss: 1.4882027506828308, Generator Loss: 0.12539999186992645\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 24, Discriminator Loss: 1.4234399199485779, Generator Loss: 0.1435229331254959\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 26, Discriminator Loss: 1.4543376863002777, Generator Loss: 0.1356619894504547\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 28, Discriminator Loss: 1.3578358888626099, Generator Loss: 0.16386477649211884\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 30, Discriminator Loss: 1.3097841143608093, Generator Loss: 0.1816013753414154\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 32, Discriminator Loss: 1.2123351693153381, Generator Loss: 0.22555819153785706\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 34, Discriminator Loss: 1.0998416244983673, Generator Loss: 0.287398099899292\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 36, Discriminator Loss: 1.010220229625702, Generator Loss: 0.34908562898635864\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 38, Discriminator Loss: 0.8877454102039337, Generator Loss: 0.4685896337032318\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 40, Discriminator Loss: 0.7959558069705963, Generator Loss: 0.591241180896759\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 42, Discriminator Loss: 0.724585086107254, Generator Loss: 0.712144136428833\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 44, Discriminator Loss: 0.6411330699920654, Generator Loss: 0.8959797620773315\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 46, Discriminator Loss: 0.6083662211894989, Generator Loss: 0.9755675196647644\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 48, Discriminator Loss: 0.5645891577005386, Generator Loss: 1.1148912906646729\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 50, Discriminator Loss: 0.5271039307117462, Generator Loss: 1.2562000751495361\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 52, Discriminator Loss: 0.49741819500923157, Generator Loss: 1.3936609029769897\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 54, Discriminator Loss: 0.47834526002407074, Generator Loss: 1.4959280490875244\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 56, Discriminator Loss: 0.4483778476715088, Generator Loss: 1.6853060722351074\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 58, Discriminator Loss: 0.430480994284153, Generator Loss: 1.8183889389038086\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 60, Discriminator Loss: 0.4216933399438858, Generator Loss: 1.876541256904602\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 62, Discriminator Loss: 0.41783109307289124, Generator Loss: 1.9304949045181274\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Step: 64, Discriminator Loss: 0.4108262434601784, Generator Loss: 1.962233304977417\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 66, Discriminator Loss: 0.4198821485042572, Generator Loss: 1.8500382900238037\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Step: 68, Discriminator Loss: 0.42447951436042786, Generator Loss: 1.8048419952392578\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 70, Discriminator Loss: 0.4417671114206314, Generator Loss: 1.6475589275360107\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 72, Discriminator Loss: 0.4476066529750824, Generator Loss: 1.5399270057678223\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 74, Discriminator Loss: 0.470117524266243, Generator Loss: 1.4126286506652832\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 76, Discriminator Loss: 0.4801509529352188, Generator Loss: 1.3343331813812256\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 78, Discriminator Loss: 0.48060739040374756, Generator Loss: 1.3125200271606445\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Step: 80, Discriminator Loss: 0.4861060380935669, Generator Loss: 1.2836644649505615\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 82, Discriminator Loss: 0.4790385961532593, Generator Loss: 1.3254468441009521\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 84, Discriminator Loss: 0.465570405125618, Generator Loss: 1.374739646911621\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 86, Discriminator Loss: 0.4580763727426529, Generator Loss: 1.4021888971328735\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Step: 88, Discriminator Loss: 0.46391721069812775, Generator Loss: 1.3816752433776855\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 90, Discriminator Loss: 0.46132197976112366, Generator Loss: 1.3669461011886597\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 92, Discriminator Loss: 0.47398021817207336, Generator Loss: 1.3417500257492065\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 94, Discriminator Loss: 0.470179483294487, Generator Loss: 1.3089680671691895\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 96, Discriminator Loss: 0.49991142749786377, Generator Loss: 1.1859145164489746\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 98, Discriminator Loss: 0.5081782042980194, Generator Loss: 1.1035759449005127\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 100, Discriminator Loss: 0.5348662286996841, Generator Loss: 1.00613534450531\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 102, Discriminator Loss: 0.5600567162036896, Generator Loss: 0.9296880960464478\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 104, Discriminator Loss: 0.6280878484249115, Generator Loss: 0.7521061897277832\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 106, Discriminator Loss: 0.6463131606578827, Generator Loss: 0.7083889842033386\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 108, Discriminator Loss: 0.6842264831066132, Generator Loss: 0.6339802742004395\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Step: 110, Discriminator Loss: 0.7174387872219086, Generator Loss: 0.5755819082260132\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Step: 112, Discriminator Loss: 0.7618791460990906, Generator Loss: 0.5212185382843018\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 114, Discriminator Loss: 0.7621257305145264, Generator Loss: 0.5245600342750549\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 116, Discriminator Loss: 0.7849861085414886, Generator Loss: 0.491277813911438\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 118, Discriminator Loss: 0.8078145384788513, Generator Loss: 0.47186005115509033\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 120, Discriminator Loss: 0.8037552237510681, Generator Loss: 0.4744449555873871\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Step: 122, Discriminator Loss: 0.7946065068244934, Generator Loss: 0.48710012435913086\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 124, Discriminator Loss: 0.7861491739749908, Generator Loss: 0.5058192014694214\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 126, Discriminator Loss: 0.7864019274711609, Generator Loss: 0.5058828592300415\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Step: 128, Discriminator Loss: 0.7733003497123718, Generator Loss: 0.5257346034049988\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 130, Discriminator Loss: 0.7721157968044281, Generator Loss: 0.531662106513977\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 132, Discriminator Loss: 0.7493489682674408, Generator Loss: 0.564589262008667\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 134, Discriminator Loss: 0.7558612823486328, Generator Loss: 0.5636978149414062\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 136, Discriminator Loss: 0.7649202942848206, Generator Loss: 0.5548936128616333\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 138, Discriminator Loss: 0.7346383333206177, Generator Loss: 0.6013062596321106\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 140, Discriminator Loss: 0.7367973923683167, Generator Loss: 0.611457884311676\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 142, Discriminator Loss: 0.7012862861156464, Generator Loss: 0.6749156713485718\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 144, Discriminator Loss: 0.7035599946975708, Generator Loss: 0.6793267130851746\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 146, Discriminator Loss: 0.6766456961631775, Generator Loss: 0.7273732423782349\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Step: 148, Discriminator Loss: 0.6422900259494781, Generator Loss: 0.8212375044822693\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 150, Discriminator Loss: 0.619010329246521, Generator Loss: 0.8842525482177734\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Step: 152, Discriminator Loss: 0.6070715188980103, Generator Loss: 0.9425275325775146\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 154, Discriminator Loss: 0.5788576006889343, Generator Loss: 1.0344945192337036\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 156, Discriminator Loss: 0.55795519053936, Generator Loss: 1.1384756565093994\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 158, Discriminator Loss: 0.5603923797607422, Generator Loss: 1.1266433000564575\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 160, Discriminator Loss: 0.5541948080062866, Generator Loss: 1.1603717803955078\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Step: 162, Discriminator Loss: 0.5410999059677124, Generator Loss: 1.2390464544296265\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 164, Discriminator Loss: 0.5318715125322342, Generator Loss: 1.282334804534912\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Step: 166, Discriminator Loss: 0.5189768970012665, Generator Loss: 1.3540529012680054\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 168, Discriminator Loss: 0.5239416360855103, Generator Loss: 1.3385238647460938\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 170, Discriminator Loss: 0.5305756032466888, Generator Loss: 1.3079453706741333\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 172, Discriminator Loss: 0.5287922322750092, Generator Loss: 1.3170225620269775\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 174, Discriminator Loss: 0.5331388413906097, Generator Loss: 1.303093671798706\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 176, Discriminator Loss: 0.543440192937851, Generator Loss: 1.2350339889526367\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 178, Discriminator Loss: 0.5500808656215668, Generator Loss: 1.2157937288284302\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 180, Discriminator Loss: 0.5528713911771774, Generator Loss: 1.1946265697479248\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 18ms/step\n",
      "Step: 182, Discriminator Loss: 0.57291479408741, Generator Loss: 1.0934576988220215\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Step: 184, Discriminator Loss: 0.5840462148189545, Generator Loss: 1.0497817993164062\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 186, Discriminator Loss: 0.5879532694816589, Generator Loss: 1.0367838144302368\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Step: 188, Discriminator Loss: 0.6008109450340271, Generator Loss: 0.9936328530311584\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 190, Discriminator Loss: 0.617913693189621, Generator Loss: 0.9323183298110962\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Step: 192, Discriminator Loss: 0.622389554977417, Generator Loss: 0.9250875115394592\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 194, Discriminator Loss: 0.6402719914913177, Generator Loss: 0.8715208768844604\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 196, Discriminator Loss: 0.6426089406013489, Generator Loss: 0.8594580888748169\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 198, Discriminator Loss: 0.6521711945533752, Generator Loss: 0.820762038230896\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 200, Discriminator Loss: 0.6639205813407898, Generator Loss: 0.8100340366363525\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Step: 202, Discriminator Loss: 0.6760427355766296, Generator Loss: 0.7667837142944336\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 204, Discriminator Loss: 0.6763248443603516, Generator Loss: 0.7659787535667419\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 206, Discriminator Loss: 0.6895973086357117, Generator Loss: 0.7403604984283447\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 208, Discriminator Loss: 0.689931184053421, Generator Loss: 0.7407127618789673\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Step: 210, Discriminator Loss: 0.7022358775138855, Generator Loss: 0.7111533880233765\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 212, Discriminator Loss: 0.7006558775901794, Generator Loss: 0.7152734994888306\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 214, Discriminator Loss: 0.705208957195282, Generator Loss: 0.7063286900520325\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 216, Discriminator Loss: 0.709514319896698, Generator Loss: 0.6975853443145752\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 218, Discriminator Loss: 0.7058294117450714, Generator Loss: 0.7000561952590942\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 220, Discriminator Loss: 0.7114534378051758, Generator Loss: 0.6889886856079102\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 222, Discriminator Loss: 0.7101931869983673, Generator Loss: 0.6895845532417297\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 224, Discriminator Loss: 0.7126110792160034, Generator Loss: 0.6846124529838562\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 226, Discriminator Loss: 0.7136380076408386, Generator Loss: 0.6790578365325928\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 228, Discriminator Loss: 0.7158699333667755, Generator Loss: 0.6832301616668701\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 230, Discriminator Loss: 0.7123651802539825, Generator Loss: 0.6832307577133179\n",
      "2/2 [==============================] - 0s 778us/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 232, Discriminator Loss: 0.7143263220787048, Generator Loss: 0.6779109835624695\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 234, Discriminator Loss: 0.7146364152431488, Generator Loss: 0.6759835481643677\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Step: 236, Discriminator Loss: 0.7164496183395386, Generator Loss: 0.6714169979095459\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 238, Discriminator Loss: 0.7159115076065063, Generator Loss: 0.6768301725387573\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 240, Discriminator Loss: 0.7127346098423004, Generator Loss: 0.678598165512085\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 242, Discriminator Loss: 0.7146673798561096, Generator Loss: 0.6725085973739624\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 244, Discriminator Loss: 0.7138184607028961, Generator Loss: 0.6739084720611572\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 246, Discriminator Loss: 0.7144957482814789, Generator Loss: 0.6811277270317078\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 248, Discriminator Loss: 0.7138828933238983, Generator Loss: 0.6749117970466614\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 250, Discriminator Loss: 0.715431809425354, Generator Loss: 0.6735791563987732\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 252, Discriminator Loss: 0.7151651978492737, Generator Loss: 0.677371084690094\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 254, Discriminator Loss: 0.7141667008399963, Generator Loss: 0.6775213479995728\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 256, Discriminator Loss: 0.7130195498466492, Generator Loss: 0.6728273630142212\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 258, Discriminator Loss: 0.712858259677887, Generator Loss: 0.672126293182373\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 260, Discriminator Loss: 0.7162763178348541, Generator Loss: 0.673263430595398\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 262, Discriminator Loss: 0.7116467654705048, Generator Loss: 0.6778090000152588\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 264, Discriminator Loss: 0.71369469165802, Generator Loss: 0.674020528793335\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 266, Discriminator Loss: 0.7114835977554321, Generator Loss: 0.6795327663421631\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 268, Discriminator Loss: 0.7105669379234314, Generator Loss: 0.678166389465332\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 270, Discriminator Loss: 0.7112126350402832, Generator Loss: 0.6789414286613464\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 272, Discriminator Loss: 0.7107630372047424, Generator Loss: 0.6792973279953003\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 274, Discriminator Loss: 0.712558388710022, Generator Loss: 0.6774859428405762\n",
      "2/2 [==============================] - 0s 508us/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 276, Discriminator Loss: 0.7113869786262512, Generator Loss: 0.6783451437950134\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 278, Discriminator Loss: 0.7090193033218384, Generator Loss: 0.6830712556838989\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 280, Discriminator Loss: 0.71202152967453, Generator Loss: 0.6771484613418579\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 282, Discriminator Loss: 0.7108973860740662, Generator Loss: 0.6755045652389526\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 284, Discriminator Loss: 0.7103245258331299, Generator Loss: 0.6756094098091125\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 286, Discriminator Loss: 0.7118469774723053, Generator Loss: 0.6792969703674316\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 288, Discriminator Loss: 0.7104808688163757, Generator Loss: 0.6762697696685791\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Step: 290, Discriminator Loss: 0.7080837488174438, Generator Loss: 0.6785140037536621\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 292, Discriminator Loss: 0.7120890021324158, Generator Loss: 0.6747598052024841\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 294, Discriminator Loss: 0.7098517417907715, Generator Loss: 0.6816436052322388\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 296, Discriminator Loss: 0.7104867398738861, Generator Loss: 0.6778218746185303\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 298, Discriminator Loss: 0.7071133852005005, Generator Loss: 0.680342435836792\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 300, Discriminator Loss: 0.7099142372608185, Generator Loss: 0.676588773727417\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 302, Discriminator Loss: 0.7093472480773926, Generator Loss: 0.6764194965362549\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 304, Discriminator Loss: 0.7111271023750305, Generator Loss: 0.6780466437339783\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 306, Discriminator Loss: 0.7075605094432831, Generator Loss: 0.6811701655387878\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 308, Discriminator Loss: 0.7066281735897064, Generator Loss: 0.6819496750831604\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 310, Discriminator Loss: 0.708282470703125, Generator Loss: 0.6828513741493225\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 312, Discriminator Loss: 0.7096006274223328, Generator Loss: 0.680180549621582\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 314, Discriminator Loss: 0.707284152507782, Generator Loss: 0.682829737663269\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 316, Discriminator Loss: 0.7080720663070679, Generator Loss: 0.6799483895301819\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 318, Discriminator Loss: 0.7069098949432373, Generator Loss: 0.6914187669754028\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 320, Discriminator Loss: 0.7080463767051697, Generator Loss: 0.6796360015869141\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 322, Discriminator Loss: 0.7066367268562317, Generator Loss: 0.6807163953781128\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 324, Discriminator Loss: 0.7073244452476501, Generator Loss: 0.6798467636108398\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 326, Discriminator Loss: 0.7075664699077606, Generator Loss: 0.6847385168075562\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 328, Discriminator Loss: 0.7074075937271118, Generator Loss: 0.6817055940628052\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 330, Discriminator Loss: 0.7058371305465698, Generator Loss: 0.6820512413978577\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 332, Discriminator Loss: 0.7052364647388458, Generator Loss: 0.6817003488540649\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 334, Discriminator Loss: 0.7059530317783356, Generator Loss: 0.6820899844169617\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 336, Discriminator Loss: 0.7068148255348206, Generator Loss: 0.6836715936660767\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 338, Discriminator Loss: 0.7052771151065826, Generator Loss: 0.6822052001953125\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 340, Discriminator Loss: 0.7059460282325745, Generator Loss: 0.684004545211792\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 342, Discriminator Loss: 0.7068671882152557, Generator Loss: 0.6838199496269226\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 344, Discriminator Loss: 0.707552045583725, Generator Loss: 0.6840251684188843\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 346, Discriminator Loss: 0.7051436305046082, Generator Loss: 0.6817114353179932\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 348, Discriminator Loss: 0.705819696187973, Generator Loss: 0.6860272884368896\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 350, Discriminator Loss: 0.7048718929290771, Generator Loss: 0.6863499879837036\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 352, Discriminator Loss: 0.7059104442596436, Generator Loss: 0.6880645751953125\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 354, Discriminator Loss: 0.7059648633003235, Generator Loss: 0.685202419757843\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 356, Discriminator Loss: 0.7070203125476837, Generator Loss: 0.6841961741447449\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 358, Discriminator Loss: 0.7059929072856903, Generator Loss: 0.6841665506362915\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 360, Discriminator Loss: 0.705141693353653, Generator Loss: 0.6849194765090942\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 362, Discriminator Loss: 0.7056286036968231, Generator Loss: 0.6849167943000793\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 364, Discriminator Loss: 0.7056292295455933, Generator Loss: 0.6838014125823975\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 366, Discriminator Loss: 0.7037312090396881, Generator Loss: 0.6849663853645325\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 368, Discriminator Loss: 0.702103316783905, Generator Loss: 0.6865165829658508\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 370, Discriminator Loss: 0.7052457332611084, Generator Loss: 0.690240740776062\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 372, Discriminator Loss: 0.7055492997169495, Generator Loss: 0.6872438192367554\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 374, Discriminator Loss: 0.7057435512542725, Generator Loss: 0.6899998188018799\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 376, Discriminator Loss: 0.7045354247093201, Generator Loss: 0.6859350800514221\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 378, Discriminator Loss: 0.7062783241271973, Generator Loss: 0.6863811016082764\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 380, Discriminator Loss: 0.7029074430465698, Generator Loss: 0.6893312931060791\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 382, Discriminator Loss: 0.7056057155132294, Generator Loss: 0.6884521245956421\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 384, Discriminator Loss: 0.7050087153911591, Generator Loss: 0.688606858253479\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 386, Discriminator Loss: 0.7037191092967987, Generator Loss: 0.6901781558990479\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 388, Discriminator Loss: 0.7042717933654785, Generator Loss: 0.6903548836708069\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 390, Discriminator Loss: 0.7033208310604095, Generator Loss: 0.6872833371162415\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 392, Discriminator Loss: 0.702722430229187, Generator Loss: 0.6887586712837219\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 394, Discriminator Loss: 0.7033509612083435, Generator Loss: 0.6885660886764526\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 396, Discriminator Loss: 0.7042272388935089, Generator Loss: 0.6952135562896729\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 398, Discriminator Loss: 0.7046792805194855, Generator Loss: 0.6886569261550903\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 400, Discriminator Loss: 0.7027093172073364, Generator Loss: 0.6884670257568359\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 402, Discriminator Loss: 0.7024621963500977, Generator Loss: 0.6868120431900024\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 404, Discriminator Loss: 0.7024771571159363, Generator Loss: 0.6924836039543152\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 406, Discriminator Loss: 0.7026325464248657, Generator Loss: 0.6911952495574951\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 408, Discriminator Loss: 0.70378577709198, Generator Loss: 0.6876295804977417\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 410, Discriminator Loss: 0.701749324798584, Generator Loss: 0.6889556646347046\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 412, Discriminator Loss: 0.7028067111968994, Generator Loss: 0.6925904750823975\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 414, Discriminator Loss: 0.7012447118759155, Generator Loss: 0.6884479522705078\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 416, Discriminator Loss: 0.7022763192653656, Generator Loss: 0.6925801038742065\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 418, Discriminator Loss: 0.7037419676780701, Generator Loss: 0.6913690567016602\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 420, Discriminator Loss: 0.703370064496994, Generator Loss: 0.6905854344367981\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 422, Discriminator Loss: 0.7033111751079559, Generator Loss: 0.6916356086730957\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 424, Discriminator Loss: 0.7020463943481445, Generator Loss: 0.6882145404815674\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 426, Discriminator Loss: 0.7032473981380463, Generator Loss: 0.6937888860702515\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 428, Discriminator Loss: 0.7023935616016388, Generator Loss: 0.690631628036499\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 430, Discriminator Loss: 0.703313559293747, Generator Loss: 0.6898294687271118\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 432, Discriminator Loss: 0.7043782472610474, Generator Loss: 0.690430760383606\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 434, Discriminator Loss: 0.702879786491394, Generator Loss: 0.6932257413864136\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 436, Discriminator Loss: 0.7023075819015503, Generator Loss: 0.692253828048706\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 438, Discriminator Loss: 0.7019249200820923, Generator Loss: 0.6948150396347046\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 440, Discriminator Loss: 0.7016259431838989, Generator Loss: 0.6931018829345703\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 442, Discriminator Loss: 0.7019125521183014, Generator Loss: 0.6943868398666382\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 444, Discriminator Loss: 0.7023726999759674, Generator Loss: 0.6921155452728271\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 446, Discriminator Loss: 0.7008110284805298, Generator Loss: 0.6909818649291992\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 448, Discriminator Loss: 0.7020667791366577, Generator Loss: 0.696884036064148\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 450, Discriminator Loss: 0.7022237777709961, Generator Loss: 0.6955015659332275\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 452, Discriminator Loss: 0.7013390362262726, Generator Loss: 0.6935876607894897\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 454, Discriminator Loss: 0.6997886598110199, Generator Loss: 0.6952506899833679\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 456, Discriminator Loss: 0.7024337649345398, Generator Loss: 0.6958470344543457\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 458, Discriminator Loss: 0.70210200548172, Generator Loss: 0.6918423771858215\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 460, Discriminator Loss: 0.7008793652057648, Generator Loss: 0.6914844512939453\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 462, Discriminator Loss: 0.7007641494274139, Generator Loss: 0.69415283203125\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 464, Discriminator Loss: 0.7009799778461456, Generator Loss: 0.6912281513214111\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 466, Discriminator Loss: 0.7005170583724976, Generator Loss: 0.6970637440681458\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 468, Discriminator Loss: 0.7016714215278625, Generator Loss: 0.6939051151275635\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 470, Discriminator Loss: 0.7025881409645081, Generator Loss: 0.6933556795120239\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 472, Discriminator Loss: 0.700482189655304, Generator Loss: 0.695314884185791\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 474, Discriminator Loss: 0.7014685869216919, Generator Loss: 0.6941817402839661\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 476, Discriminator Loss: 0.7005814611911774, Generator Loss: 0.6922000646591187\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 478, Discriminator Loss: 0.7009842395782471, Generator Loss: 0.6948204636573792\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 480, Discriminator Loss: 0.700310617685318, Generator Loss: 0.6960035562515259\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 482, Discriminator Loss: 0.7012070417404175, Generator Loss: 0.6935734152793884\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 484, Discriminator Loss: 0.7015625536441803, Generator Loss: 0.6965384483337402\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 486, Discriminator Loss: 0.7013044655323029, Generator Loss: 0.693678617477417\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 488, Discriminator Loss: 0.6995319724082947, Generator Loss: 0.693171501159668\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 490, Discriminator Loss: 0.6993805766105652, Generator Loss: 0.6965381503105164\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 492, Discriminator Loss: 0.7002255916595459, Generator Loss: 0.6970502138137817\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 494, Discriminator Loss: 0.7004744410514832, Generator Loss: 0.6972275972366333\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 496, Discriminator Loss: 0.7004057168960571, Generator Loss: 0.6975889205932617\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 498, Discriminator Loss: 0.7001743018627167, Generator Loss: 0.6974856853485107\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 500, Discriminator Loss: 0.6999315321445465, Generator Loss: 0.6967988014221191\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 502, Discriminator Loss: 0.6985231637954712, Generator Loss: 0.6970775127410889\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 504, Discriminator Loss: 0.6998790800571442, Generator Loss: 0.6947894096374512\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 506, Discriminator Loss: 0.6991308629512787, Generator Loss: 0.699981689453125\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 508, Discriminator Loss: 0.6995373368263245, Generator Loss: 0.6939725875854492\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 510, Discriminator Loss: 0.7001259326934814, Generator Loss: 0.6954092979431152\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 512, Discriminator Loss: 0.6987461149692535, Generator Loss: 0.6974461078643799\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 514, Discriminator Loss: 0.7012174129486084, Generator Loss: 0.6930873990058899\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 516, Discriminator Loss: 0.7006969451904297, Generator Loss: 0.6975365877151489\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 518, Discriminator Loss: 0.6987588703632355, Generator Loss: 0.698639988899231\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 520, Discriminator Loss: 0.6995987892150879, Generator Loss: 0.6968713998794556\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 522, Discriminator Loss: 0.6987600326538086, Generator Loss: 0.6989117860794067\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 524, Discriminator Loss: 0.6994305849075317, Generator Loss: 0.6966308951377869\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 526, Discriminator Loss: 0.7001214325428009, Generator Loss: 0.6968690156936646\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 528, Discriminator Loss: 0.6988725066184998, Generator Loss: 0.6965135931968689\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 530, Discriminator Loss: 0.6993846297264099, Generator Loss: 0.6958059072494507\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 532, Discriminator Loss: 0.6994810700416565, Generator Loss: 0.6982131004333496\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 534, Discriminator Loss: 0.7016256749629974, Generator Loss: 0.694924533367157\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 536, Discriminator Loss: 0.6996198296546936, Generator Loss: 0.6953089237213135\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 538, Discriminator Loss: 0.696930319070816, Generator Loss: 0.6991917490959167\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 540, Discriminator Loss: 0.6994615197181702, Generator Loss: 0.6978307962417603\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 542, Discriminator Loss: 0.6984917521476746, Generator Loss: 0.6972113847732544\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 544, Discriminator Loss: 0.7001208662986755, Generator Loss: 0.6978436708450317\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 546, Discriminator Loss: 0.7002453505992889, Generator Loss: 0.6960523128509521\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 548, Discriminator Loss: 0.6986625790596008, Generator Loss: 0.7011147737503052\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 550, Discriminator Loss: 0.6994129717350006, Generator Loss: 0.6965048313140869\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 552, Discriminator Loss: 0.698185384273529, Generator Loss: 0.6972687244415283\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 554, Discriminator Loss: 0.6986294686794281, Generator Loss: 0.6986171007156372\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 556, Discriminator Loss: 0.6990580558776855, Generator Loss: 0.6962757110595703\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 558, Discriminator Loss: 0.6994320154190063, Generator Loss: 0.6994425058364868\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 560, Discriminator Loss: 0.6976549029350281, Generator Loss: 0.6975931525230408\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 562, Discriminator Loss: 0.6985707581043243, Generator Loss: 0.695887565612793\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 564, Discriminator Loss: 0.6989960074424744, Generator Loss: 0.695160448551178\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 566, Discriminator Loss: 0.6978054046630859, Generator Loss: 0.6972351670265198\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 568, Discriminator Loss: 0.6987876892089844, Generator Loss: 0.6980544328689575\n",
      "2/2 [==============================] - 0s 772us/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 570, Discriminator Loss: 0.6964053511619568, Generator Loss: 0.7002320885658264\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 572, Discriminator Loss: 0.6972317695617676, Generator Loss: 0.6983112096786499\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Step: 574, Discriminator Loss: 0.6977247893810272, Generator Loss: 0.7000054121017456\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 576, Discriminator Loss: 0.6974045634269714, Generator Loss: 0.698689341545105\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 578, Discriminator Loss: 0.6974141299724579, Generator Loss: 0.6991026401519775\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 580, Discriminator Loss: 0.6967333555221558, Generator Loss: 0.6976413726806641\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 582, Discriminator Loss: 0.7001437246799469, Generator Loss: 0.696238100528717\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 584, Discriminator Loss: 0.6987772583961487, Generator Loss: 0.6946629285812378\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 586, Discriminator Loss: 0.6973695456981659, Generator Loss: 0.7002550363540649\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 588, Discriminator Loss: 0.6967044770717621, Generator Loss: 0.6991034150123596\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 590, Discriminator Loss: 0.6974039077758789, Generator Loss: 0.6982893943786621\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 592, Discriminator Loss: 0.6995577216148376, Generator Loss: 0.7016350626945496\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Step: 594, Discriminator Loss: 0.6977199912071228, Generator Loss: 0.6965328454971313\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 596, Discriminator Loss: 0.697481095790863, Generator Loss: 0.6992214918136597\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 598, Discriminator Loss: 0.6973468363285065, Generator Loss: 0.6956251263618469\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 600, Discriminator Loss: 0.6974785625934601, Generator Loss: 0.6991252303123474\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 602, Discriminator Loss: 0.6972119212150574, Generator Loss: 0.6983520984649658\n",
      "2/2 [==============================] - 0s 554us/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 604, Discriminator Loss: 0.6974695026874542, Generator Loss: 0.7014440298080444\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 606, Discriminator Loss: 0.6963569223880768, Generator Loss: 0.6995865106582642\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 608, Discriminator Loss: 0.6969152987003326, Generator Loss: 0.7004610300064087\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 610, Discriminator Loss: 0.6961009502410889, Generator Loss: 0.70243239402771\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 612, Discriminator Loss: 0.696540355682373, Generator Loss: 0.7019892334938049\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 614, Discriminator Loss: 0.697346031665802, Generator Loss: 0.7040056586265564\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 616, Discriminator Loss: 0.6985779404640198, Generator Loss: 0.7021233439445496\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 618, Discriminator Loss: 0.6974031925201416, Generator Loss: 0.7015022039413452\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 620, Discriminator Loss: 0.6970589756965637, Generator Loss: 0.7022941708564758\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 622, Discriminator Loss: 0.6972932517528534, Generator Loss: 0.7011291980743408\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 624, Discriminator Loss: 0.6964893639087677, Generator Loss: 0.7008703947067261\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 626, Discriminator Loss: 0.6980253159999847, Generator Loss: 0.6997162103652954\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 628, Discriminator Loss: 0.6966872215270996, Generator Loss: 0.7029651403427124\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 630, Discriminator Loss: 0.6969078183174133, Generator Loss: 0.7025418877601624\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 632, Discriminator Loss: 0.6974042057991028, Generator Loss: 0.6995772123336792\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 634, Discriminator Loss: 0.6971437931060791, Generator Loss: 0.7034394145011902\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 636, Discriminator Loss: 0.6977488696575165, Generator Loss: 0.6997948288917542\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 638, Discriminator Loss: 0.6970497667789459, Generator Loss: 0.7020782232284546\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 640, Discriminator Loss: 0.6982283294200897, Generator Loss: 0.6991125345230103\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 642, Discriminator Loss: 0.6975501179695129, Generator Loss: 0.7014708518981934\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 644, Discriminator Loss: 0.6983964145183563, Generator Loss: 0.7016425132751465\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 646, Discriminator Loss: 0.6969937384128571, Generator Loss: 0.7014155387878418\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 648, Discriminator Loss: 0.6973539590835571, Generator Loss: 0.7001231908798218\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 650, Discriminator Loss: 0.697100043296814, Generator Loss: 0.7028682231903076\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 652, Discriminator Loss: 0.6972991526126862, Generator Loss: 0.7028012275695801\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 654, Discriminator Loss: 0.6972876191139221, Generator Loss: 0.6997014284133911\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 656, Discriminator Loss: 0.6989986896514893, Generator Loss: 0.700613260269165\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 658, Discriminator Loss: 0.6981533467769623, Generator Loss: 0.698959231376648\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 660, Discriminator Loss: 0.6973945498466492, Generator Loss: 0.700904905796051\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 662, Discriminator Loss: 0.6971539855003357, Generator Loss: 0.6997197270393372\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 664, Discriminator Loss: 0.6971856653690338, Generator Loss: 0.700258731842041\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 666, Discriminator Loss: 0.6985812187194824, Generator Loss: 0.6989025473594666\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 668, Discriminator Loss: 0.697168231010437, Generator Loss: 0.702040433883667\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 670, Discriminator Loss: 0.6986995041370392, Generator Loss: 0.7012687921524048\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 672, Discriminator Loss: 0.6972467005252838, Generator Loss: 0.7029536962509155\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 674, Discriminator Loss: 0.6976884603500366, Generator Loss: 0.7008553743362427\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 17ms/step\n",
      "Step: 676, Discriminator Loss: 0.695753425359726, Generator Loss: 0.702476978302002\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 678, Discriminator Loss: 0.6982885599136353, Generator Loss: 0.7026785612106323\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 680, Discriminator Loss: 0.6983115673065186, Generator Loss: 0.7047929763793945\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 682, Discriminator Loss: 0.6975963413715363, Generator Loss: 0.6974513530731201\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 684, Discriminator Loss: 0.6965523362159729, Generator Loss: 0.700502872467041\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 686, Discriminator Loss: 0.6959072351455688, Generator Loss: 0.702004075050354\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 688, Discriminator Loss: 0.696083277463913, Generator Loss: 0.7024946212768555\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 690, Discriminator Loss: 0.6962959468364716, Generator Loss: 0.6999070048332214\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 692, Discriminator Loss: 0.6963481307029724, Generator Loss: 0.6988968849182129\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 694, Discriminator Loss: 0.696156769990921, Generator Loss: 0.700015664100647\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 696, Discriminator Loss: 0.6958809196949005, Generator Loss: 0.7002103924751282\n",
      "2/2 [==============================] - 0s 19ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 698, Discriminator Loss: 0.6957190036773682, Generator Loss: 0.7035378813743591\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 700, Discriminator Loss: 0.6955568790435791, Generator Loss: 0.7014511823654175\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 702, Discriminator Loss: 0.6953011155128479, Generator Loss: 0.7020846605300903\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 704, Discriminator Loss: 0.696204662322998, Generator Loss: 0.7013707160949707\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 706, Discriminator Loss: 0.6963289678096771, Generator Loss: 0.6999316215515137\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 708, Discriminator Loss: 0.6961472630500793, Generator Loss: 0.7013318538665771\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 710, Discriminator Loss: 0.6954306960105896, Generator Loss: 0.6995775699615479\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 712, Discriminator Loss: 0.6981326043605804, Generator Loss: 0.6966676712036133\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 714, Discriminator Loss: 0.6963322162628174, Generator Loss: 0.7006551623344421\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 716, Discriminator Loss: 0.6950599551200867, Generator Loss: 0.6984495520591736\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 718, Discriminator Loss: 0.6964677274227142, Generator Loss: 0.6950380802154541\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Step: 720, Discriminator Loss: 0.696686714887619, Generator Loss: 0.6961593627929688\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 722, Discriminator Loss: 0.6972649991512299, Generator Loss: 0.6945322751998901\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 724, Discriminator Loss: 0.696636289358139, Generator Loss: 0.69640052318573\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 726, Discriminator Loss: 0.6970544159412384, Generator Loss: 0.6952634453773499\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 728, Discriminator Loss: 0.6971778571605682, Generator Loss: 0.6941142082214355\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 730, Discriminator Loss: 0.6958690881729126, Generator Loss: 0.695529580116272\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 732, Discriminator Loss: 0.6984880268573761, Generator Loss: 0.6939684152603149\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 734, Discriminator Loss: 0.6960618793964386, Generator Loss: 0.6943016052246094\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 736, Discriminator Loss: 0.6959146559238434, Generator Loss: 0.6956804394721985\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 738, Discriminator Loss: 0.695295661687851, Generator Loss: 0.6947778463363647\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 740, Discriminator Loss: 0.6969583332538605, Generator Loss: 0.6945351958274841\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 742, Discriminator Loss: 0.696110725402832, Generator Loss: 0.6916426420211792\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 744, Discriminator Loss: 0.6961459219455719, Generator Loss: 0.6902886629104614\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 746, Discriminator Loss: 0.6943455636501312, Generator Loss: 0.6955540180206299\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 748, Discriminator Loss: 0.6936024129390717, Generator Loss: 0.6952083110809326\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 750, Discriminator Loss: 0.6939902901649475, Generator Loss: 0.6954249143600464\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 752, Discriminator Loss: 0.6941269338130951, Generator Loss: 0.6957141160964966\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 754, Discriminator Loss: 0.6930409371852875, Generator Loss: 0.6967868804931641\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 756, Discriminator Loss: 0.6945724785327911, Generator Loss: 0.6958235502243042\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 758, Discriminator Loss: 0.69454026222229, Generator Loss: 0.6971834897994995\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 760, Discriminator Loss: 0.6944827139377594, Generator Loss: 0.6961367130279541\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 762, Discriminator Loss: 0.6942390203475952, Generator Loss: 0.6960014700889587\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 764, Discriminator Loss: 0.6943009793758392, Generator Loss: 0.6942782402038574\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 766, Discriminator Loss: 0.6953338086605072, Generator Loss: 0.6933987140655518\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 768, Discriminator Loss: 0.6946417987346649, Generator Loss: 0.6913446187973022\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 770, Discriminator Loss: 0.6951769292354584, Generator Loss: 0.6901450157165527\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 772, Discriminator Loss: 0.6959165632724762, Generator Loss: 0.6895467638969421\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 774, Discriminator Loss: 0.6978473365306854, Generator Loss: 0.6866832971572876\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 776, Discriminator Loss: 0.6978123784065247, Generator Loss: 0.6846038103103638\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 778, Discriminator Loss: 0.6985626816749573, Generator Loss: 0.6871381998062134\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 780, Discriminator Loss: 0.699874609708786, Generator Loss: 0.6864928603172302\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 782, Discriminator Loss: 0.6999092102050781, Generator Loss: 0.6836830377578735\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 784, Discriminator Loss: 0.6986755728721619, Generator Loss: 0.6869364380836487\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 786, Discriminator Loss: 0.6985875368118286, Generator Loss: 0.6845376491546631\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 788, Discriminator Loss: 0.7003535032272339, Generator Loss: 0.6817923784255981\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 790, Discriminator Loss: 0.6996671557426453, Generator Loss: 0.6837491393089294\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 792, Discriminator Loss: 0.6992660164833069, Generator Loss: 0.6840969920158386\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 794, Discriminator Loss: 0.6990691423416138, Generator Loss: 0.6850112676620483\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 796, Discriminator Loss: 0.7004835307598114, Generator Loss: 0.6889381408691406\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 798, Discriminator Loss: 0.6988662481307983, Generator Loss: 0.687287449836731\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 800, Discriminator Loss: 0.6982235610485077, Generator Loss: 0.6901034712791443\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 802, Discriminator Loss: 0.6988103985786438, Generator Loss: 0.6867027878761292\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 804, Discriminator Loss: 0.698178768157959, Generator Loss: 0.6923584938049316\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 806, Discriminator Loss: 0.6981903314590454, Generator Loss: 0.688675045967102\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "Step: 808, Discriminator Loss: 0.6974343061447144, Generator Loss: 0.6917940378189087\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 810, Discriminator Loss: 0.6964316368103027, Generator Loss: 0.6933172941207886\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 812, Discriminator Loss: 0.6969541907310486, Generator Loss: 0.6940481662750244\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 20ms/step\n",
      "Step: 814, Discriminator Loss: 0.6971108019351959, Generator Loss: 0.6919452548027039\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 816, Discriminator Loss: 0.6968603134155273, Generator Loss: 0.6953932046890259\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 818, Discriminator Loss: 0.6974270343780518, Generator Loss: 0.6965447068214417\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 820, Discriminator Loss: 0.6960740685462952, Generator Loss: 0.695732593536377\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 822, Discriminator Loss: 0.6957163214683533, Generator Loss: 0.6979820132255554\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "Step: 824, Discriminator Loss: 0.696794867515564, Generator Loss: 0.6969537734985352\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 826, Discriminator Loss: 0.6952528059482574, Generator Loss: 0.6971161961555481\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 828, Discriminator Loss: 0.6962852776050568, Generator Loss: 0.7014720439910889\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 830, Discriminator Loss: 0.6962100267410278, Generator Loss: 0.6985527276992798\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 832, Discriminator Loss: 0.6949787139892578, Generator Loss: 0.6990841627120972\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 834, Discriminator Loss: 0.6965202689170837, Generator Loss: 0.6984965205192566\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 836, Discriminator Loss: 0.6965207159519196, Generator Loss: 0.6996462941169739\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 838, Discriminator Loss: 0.6967765092849731, Generator Loss: 0.6979446411132812\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 840, Discriminator Loss: 0.6970047950744629, Generator Loss: 0.6992209553718567\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Step: 842, Discriminator Loss: 0.6957866251468658, Generator Loss: 0.7000659108161926\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 844, Discriminator Loss: 0.6971442401409149, Generator Loss: 0.7010444402694702\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 846, Discriminator Loss: 0.6959742903709412, Generator Loss: 0.6990576982498169\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 848, Discriminator Loss: 0.6950174570083618, Generator Loss: 0.700876772403717\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 850, Discriminator Loss: 0.6977291405200958, Generator Loss: 0.700380802154541\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 852, Discriminator Loss: 0.6967653036117554, Generator Loss: 0.7008158564567566\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 854, Discriminator Loss: 0.6955147385597229, Generator Loss: 0.7014466524124146\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Step: 856, Discriminator Loss: 0.6969377398490906, Generator Loss: 0.6990072727203369\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 858, Discriminator Loss: 0.6965663433074951, Generator Loss: 0.6996400356292725\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 860, Discriminator Loss: 0.6955261826515198, Generator Loss: 0.701594352722168\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 862, Discriminator Loss: 0.6962797939777374, Generator Loss: 0.7035094499588013\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 864, Discriminator Loss: 0.6958996057510376, Generator Loss: 0.7025268077850342\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 866, Discriminator Loss: 0.6955068707466125, Generator Loss: 0.7028863430023193\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "2/2 [==============================] - 0s 1ms/step\n",
      "Step: 868, Discriminator Loss: 0.695828914642334, Generator Loss: 0.7015432715415955\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 870, Discriminator Loss: 0.6952705681324005, Generator Loss: 0.7046322822570801\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 518us/step\n",
      "Step: 872, Discriminator Loss: 0.6949928104877472, Generator Loss: 0.7028037309646606\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 874, Discriminator Loss: 0.6966426968574524, Generator Loss: 0.6996384859085083\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 15ms/step\n",
      "Step: 876, Discriminator Loss: 0.6963187456130981, Generator Loss: 0.699063777923584\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 878, Discriminator Loss: 0.6965277194976807, Generator Loss: 0.7038153409957886\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 880, Discriminator Loss: 0.6962995231151581, Generator Loss: 0.7043983936309814\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 882, Discriminator Loss: 0.6957226991653442, Generator Loss: 0.7035086154937744\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 884, Discriminator Loss: 0.6954063475131989, Generator Loss: 0.7025800943374634\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 886, Discriminator Loss: 0.6957442462444305, Generator Loss: 0.699786365032196\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 888, Discriminator Loss: 0.6963910162448883, Generator Loss: 0.6990419030189514\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 890, Discriminator Loss: 0.6955384612083435, Generator Loss: 0.7025430202484131\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 892, Discriminator Loss: 0.6960617005825043, Generator Loss: 0.7006337642669678\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 894, Discriminator Loss: 0.6961382627487183, Generator Loss: 0.7030858993530273\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 896, Discriminator Loss: 0.6963449120521545, Generator Loss: 0.6995458006858826\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 898, Discriminator Loss: 0.6955735385417938, Generator Loss: 0.7007609009742737\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 900, Discriminator Loss: 0.6952529549598694, Generator Loss: 0.7033472657203674\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 902, Discriminator Loss: 0.6954078376293182, Generator Loss: 0.7026737332344055\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 904, Discriminator Loss: 0.69430872797966, Generator Loss: 0.7027708888053894\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 906, Discriminator Loss: 0.6951642036437988, Generator Loss: 0.7042268514633179\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 908, Discriminator Loss: 0.6947882771492004, Generator Loss: 0.7024922370910645\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 910, Discriminator Loss: 0.6947776675224304, Generator Loss: 0.7014254927635193\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 912, Discriminator Loss: 0.6949356198310852, Generator Loss: 0.7018968462944031\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 914, Discriminator Loss: 0.6939906179904938, Generator Loss: 0.7024710774421692\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 916, Discriminator Loss: 0.6942676901817322, Generator Loss: 0.7031759023666382\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 918, Discriminator Loss: 0.6938957273960114, Generator Loss: 0.7059766054153442\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 920, Discriminator Loss: 0.6930551528930664, Generator Loss: 0.7047179937362671\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 922, Discriminator Loss: 0.6933278739452362, Generator Loss: 0.7016392946243286\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 924, Discriminator Loss: 0.6938396692276001, Generator Loss: 0.7039982080459595\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 926, Discriminator Loss: 0.6928860545158386, Generator Loss: 0.7045639753341675\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 928, Discriminator Loss: 0.6925309598445892, Generator Loss: 0.704232394695282\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 930, Discriminator Loss: 0.6928671002388, Generator Loss: 0.7025686502456665\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 932, Discriminator Loss: 0.6923317611217499, Generator Loss: 0.7025502324104309\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 9ms/step\n",
      "Step: 934, Discriminator Loss: 0.692855566740036, Generator Loss: 0.7029107809066772\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "Step: 936, Discriminator Loss: 0.693161278963089, Generator Loss: 0.7032194137573242\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 938, Discriminator Loss: 0.6944668591022491, Generator Loss: 0.7034143209457397\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 940, Discriminator Loss: 0.692748486995697, Generator Loss: 0.7028634548187256\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 942, Discriminator Loss: 0.6939924657344818, Generator Loss: 0.7011513113975525\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 944, Discriminator Loss: 0.6944578289985657, Generator Loss: 0.7005705833435059\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 946, Discriminator Loss: 0.6930041611194611, Generator Loss: 0.6995499134063721\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "Step: 948, Discriminator Loss: 0.6954830288887024, Generator Loss: 0.6997618675231934\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 950, Discriminator Loss: 0.6952569484710693, Generator Loss: 0.6996986865997314\n",
      "2/2 [==============================] - 0s 8ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 952, Discriminator Loss: 0.6953969597816467, Generator Loss: 0.6985121965408325\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "Step: 954, Discriminator Loss: 0.695173442363739, Generator Loss: 0.6963201761245728\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 956, Discriminator Loss: 0.6967546343803406, Generator Loss: 0.6987653374671936\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 958, Discriminator Loss: 0.6959306299686432, Generator Loss: 0.6980367302894592\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 960, Discriminator Loss: 0.6961206197738647, Generator Loss: 0.6996318101882935\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 962, Discriminator Loss: 0.6957560777664185, Generator Loss: 0.6968212127685547\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 16ms/step\n",
      "Step: 964, Discriminator Loss: 0.6957637071609497, Generator Loss: 0.6976344585418701\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 966, Discriminator Loss: 0.6957782506942749, Generator Loss: 0.6963956356048584\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 968, Discriminator Loss: 0.6975337266921997, Generator Loss: 0.6958110332489014\n",
      "2/2 [==============================] - 0s 12ms/step\n",
      "2/2 [==============================] - 0s 14ms/step\n",
      "Step: 970, Discriminator Loss: 0.6978676021099091, Generator Loss: 0.6942182779312134\n",
      "2/2 [==============================] - 0s 11ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 972, Discriminator Loss: 0.6978461146354675, Generator Loss: 0.6937022805213928\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 974, Discriminator Loss: 0.6977807283401489, Generator Loss: 0.6947943568229675\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "Step: 976, Discriminator Loss: 0.6981423795223236, Generator Loss: 0.6967040300369263\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 3ms/step\n",
      "Step: 978, Discriminator Loss: 0.6966633200645447, Generator Loss: 0.6947888135910034\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 980, Discriminator Loss: 0.6981589198112488, Generator Loss: 0.6956247091293335\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "2/2 [==============================] - 0s 586us/step\n",
      "Step: 982, Discriminator Loss: 0.6977403461933136, Generator Loss: 0.6941394805908203\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 984, Discriminator Loss: 0.6978168785572052, Generator Loss: 0.6928842067718506\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 986, Discriminator Loss: 0.6966498494148254, Generator Loss: 0.6932010650634766\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "Step: 988, Discriminator Loss: 0.6979164779186249, Generator Loss: 0.6934340000152588\n",
      "2/2 [==============================] - 0s 0s/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 990, Discriminator Loss: 0.6972456574440002, Generator Loss: 0.6951702237129211\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 5ms/step\n",
      "Step: 992, Discriminator Loss: 0.6966906189918518, Generator Loss: 0.6959272623062134\n",
      "2/2 [==============================] - 0s 13ms/step\n",
      "2/2 [==============================] - 0s 4ms/step\n",
      "Step: 994, Discriminator Loss: 0.6985065340995789, Generator Loss: 0.6931716203689575\n",
      "2/2 [==============================] - 0s 10ms/step\n",
      "2/2 [==============================] - 0s 6ms/step\n",
      "Step: 996, Discriminator Loss: 0.6979106366634369, Generator Loss: 0.6958580613136292\n",
      "2/2 [==============================] - 0s 7ms/step\n",
      "2/2 [==============================] - 0s 2ms/step\n",
      "Step: 998, Discriminator Loss: 0.6970874667167664, Generator Loss: 0.6934717893600464\n",
      "2/2 [==============================] - 0s 7ms/step\n"
     ]
    }
   ],
   "source": [
    "# Train GAN\n",
    "dl = []\n",
    "gl = []\n",
    "for step in range(TRAINING_STEPS):\n",
    "    # Select a random batch of real data with labels\n",
    "    idx = np.random.randint(0, data.shape[0], BATCH_SIZE)\n",
    "    real_batch = data.iloc[idx].values\n",
    "    labels_batch = one_hot_labels[idx]\n",
    "\n",
    "    # Generate a batch of new data\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
    "    generated_batch = generator.predict([noise, labels_batch])\n",
    "\n",
    "    # Train the discriminator\n",
    "    real_loss = discriminator.train_on_batch([real_batch, labels_batch], np.ones((BATCH_SIZE, 1)))\n",
    "    fake_loss = discriminator.train_on_batch([generated_batch, labels_batch], np.zeros((BATCH_SIZE, 1)))\n",
    "    discriminator_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "\n",
    "    # Train the generator\n",
    "    generator_loss = gan.train_on_batch([noise, labels_batch], np.ones((BATCH_SIZE, 1)))\n",
    "    dl.append(discriminator_loss)\n",
    "    gl.append(generator_loss)\n",
    "    if step % 2 == 0:\n",
    "        print(f\"Step: {step}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1) plot of the loss of the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1d3382d8f40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAkAAAAGwCAYAAABB4NqyAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAABx7klEQVR4nO3deVxU5eIG8GcYYNg32RURN9xwwyQ0l64okpneNvWaopn9Mr1pppaVS3bLMlOra9lmWllqV7NyK6XUXHLHNBN3RWVT2UW2Ob8/Xs8sMsAMzALD8/185nMOZ86ceeeg8PCuCkmSJBARERE1IA62LgARERGRtTEAERERUYPDAEREREQNDgMQERERNTgMQERERNTgMAARERFRg8MARERERA2Oo60LUBep1Wpcu3YNnp6eUCgUti4OERERGUGSJOTn5yM0NBQODlXX8TAAGXDt2jWEhYXZuhhERERUA6mpqWjSpEmV5zAAGeDp6QlA3EAvLy8bl4aIiIiMkZeXh7CwMM3v8aowABkgN3t5eXkxABEREdUzxnRfYSdoIiIianAYgIiIiKjBYQAiIiKiBod9gIiICABQXl6O0tJSWxeDqFJOTk5QKpVmuRYDEBFRAydJEtLT05GTk2ProhBVy8fHB8HBwbWep48BiIiogZPDT2BgINzc3DgBLNVJkiTh1q1byMzMBACEhITU6noMQEREDVh5ebkm/DRq1MjWxSGqkqurKwAgMzMTgYGBtWoOs2kn6Pnz5+Oee+6Bp6cnAgMDMXToUKSkpFT7uu+++w5t2rSBi4sLoqKisHnzZr3nJUnC7NmzERISAldXV8TFxeHMmTOW+hhERPWW3OfHzc3NxiUhMo78b7W2/dVsGoB27tyJiRMn4o8//sC2bdtQWlqKAQMGoLCwsNLX7N27FyNGjMC4ceNw9OhRDB06FEOHDsWJEyc05yxYsADvv/8+li1bhv3798Pd3R3x8fG4ffu2NT4WEVG9w2Yvqi/M9W9VIUmSZJYrmUFWVhYCAwOxc+dO9O7d2+A5w4YNQ2FhITZu3Kg5du+996Jz585YtmwZJElCaGgoXnjhBUybNg0AkJubi6CgIKxYsQLDhw+vthx5eXnw9vZGbm4uZ4ImIrt2+/ZtXLhwAREREXBxcbF1cYiqVdW/WVN+f9epeYByc3MBAH5+fpWes2/fPsTFxekdi4+Px759+wAAFy5cQHp6ut453t7eiImJ0Zxzt+LiYuTl5ek9iIiIyH7VmQCkVqsxZcoU9OzZEx06dKj0vPT0dAQFBekdCwoKQnp6uuZ5+Vhl59xt/vz58Pb21jy4EjwRUf3Ut29fTJkyRfN1s2bNsGTJEou939y5c9G5c+daXePixYtQKBRITk42S5ms5e57Xd/UmQA0ceJEnDhxAqtXr7b6e8+cORO5ubmaR2pqqtXLYDGlpeJBRNQAHTx4EE8//bTFrj9t2jQkJSXV6hphYWFIS0ur8o//mrB0+Kvv6sQw+EmTJmHjxo3YtWsXmjRpUuW5wcHByMjI0DuWkZGB4OBgzfPyMd05AjIyMipN6SqVCiqVqhafoI5Sq4EuXYDiYuDvvwHHOvHtJiKymoCAAItcV5IklJeXw8PDAx4eHrW6llKp1PzuqotKSkrg7Oxs62KYnU1rgCRJwqRJk/D999/j119/RURERLWviY2NrZC2t23bhtjYWABAREQEgoOD9c7Jy8vD/v37Nec0GDk5wF9/AWfPApwGgIiMJElAYaFtHqYMyyksLMTo0aPh4eGBkJAQvPvuuxXO0a0FkSQJc+fORdOmTaFSqRAaGornnntOc25xcTFefPFFhIWFQaVSoWXLlvj8888BADt27IBCocCWLVsQHR0NlUqF3bt3V2gCGzNmDIYOHYo333wTQUFB8PHxwbx581BWVobp06fDz88PTZo0wRdffKF5zd1NYPJ7JSUloVu3bnBzc0OPHj30pok5d+4chgwZgqCgIHh4eOCee+7B9u3bNc/37dsXly5dwvPPPw+FQqE3cmrdunVo3749VCoVmjVrVuG+NWvWDK+//jpGjx4NLy8vo2vQsrOzMXr0aPj6+sLNzQ0JCQl6U9BcunQJgwcPhq+vL9zd3dG+fXvNNDbZ2dkYOXIkAgIC4OrqilatWundI0uwaZXAxIkT8c033+CHH36Ap6enpo+Ot7e3ZrKj0aNHo3Hjxpg/fz4AYPLkyejTpw/effddDBo0CKtXr8ahQ4fwySefABDD46ZMmYL//Oc/aNWqFSIiIjBr1iyEhoZi6NChNvmcNqM7ncDVq0DbtrYrCxHVG7duAbWs1KixggLA3d24c6dPn46dO3fihx9+QGBgIF5++WUcOXKk0tr+devWYfHixVi9ejXat2+P9PR0HDt2TPP86NGjsW/fPrz//vvo1KkTLly4gOvXr+td46WXXsLChQvRvHlz+Pr6YseOHRXe59dff0WTJk2wa9cu7NmzB+PGjcPevXvRu3dv7N+/H2vWrMH//d//oX///lW2erzyyit49913ERAQgGeeeQZPPvkk9uzZc+c+FeCBBx7AG2+8AZVKhS+//BKDBw9GSkoKmjZtivXr16NTp054+umnMX78eM01Dx8+jMcffxxz587FsGHDsHfvXjz77LNo1KgRxowZozlv4cKFmD17NubMmWPEd0IYM2YMzpw5gx9//BFeXl548cUX8cADD+DkyZNwcnLCxIkTUVJSgl27dsHd3R0nT57U1J7NmjULJ0+exJYtW+Dv74+zZ8+iqKjI6PeuEcmGABh8fPHFF5pz+vTpIyUmJuq9bu3atVLr1q0lZ2dnqX379tKmTZv0nler1dKsWbOkoKAgSaVSSf369ZNSUlKMLldubq4EQMrNza3Nx7O9v/6SJPEHlSR98omtS0NEdVBRUZF08uRJqaioSHOsoED7o8Paj4IC48qdn58vOTs7S2vXrtUcu3HjhuTq6ipNnjxZcyw8PFxavHixJEmS9O6770qtW7eWSkpKKlwvJSVFAiBt27bN4Pv99ttvEgBpw4YNesfnzJkjderUSfN1YmKiFB4eLpWXl2uORUZGSr169dJ8XVZWJrm7u0vffvutJEmSdOHCBQmAdPToUb332r59u+Y1mzZtkgDofZ/u1r59e+mDDz4w+Nll//rXv6T+/fvrHZs+fbrUrl07vdcNHTq00veR9enTR3OvT58+LQGQ9uzZo3n++vXrkqurq+Z7FBUVJc2dO9fgtQYPHiyNHTu22veUJMP/ZmWm/P62aQ2QZERdp6F0/dhjj+Gxxx6r9DUKhQLz5s3DvHnzalO8+q+gQLtvTx27icii3Nz0f3xY+72Nce7cOZSUlCAmJkZzzM/PD5GRkZW+5rHHHsOSJUvQvHlzDBw4EA888AAGDx4MR0dHJCcnQ6lUok+fPlW+b7du3aotW/v27eHgoO1hEhQUpNfBWalUolGjRpo1rSrTsWNHzb7cpzUzMxNNmzZFQUEB5s6di02bNiEtLQ1lZWUoKirC5cuXq7zm33//jSFDhugd69mzJ5YsWYLy8nLN0hLGfM67r+vo6Kj3/WjUqBEiIyPx999/AwCee+45TJgwAb/88gvi4uLwyCOPaD7jhAkT8Mgjj+DIkSMYMGAAhg4dih49ephUBlPVmVFgZAH5+dp9W/00I6J6R6EQzVC2eFhyQuqwsDCkpKTgww8/hKurK5599ln07t0bpaWlmm4X1XE3on3OyclJ72uFQmHwmFqtNvo6ch8e+TXTpk3D999/jzfffBO///47kpOTERUVhZKSEqM+R3WM+Zymeuqpp3D+/HmMGjUKx48fR7du3fDBBx8AABISEjR9lq5du4Z+/fppJjO2FAYge6YbeqpYXoSIqL5p0aIFnJycsH//fs2x7OxsnD59usrXubq6YvDgwXj//fexY8cO7Nu3D8ePH0dUVBTUajV27txp6aKbxZ49ezBmzBj885//RFRUFIKDg3Hx4kW9c5ydnVFeXq53rG3btpp+RLrXat26da0WFm3bti3Kysr0vh83btxASkoK2rVrpzkWFhaGZ555BuvXr8cLL7yATz/9VPNcQEAAEhMT8fXXX2PJkiWavr2WwnHR9ky3BogBiIjsiIeHB8aNG4fp06ejUaNGCAwMxCuvvKLX9HS3FStWoLy8HDExMXBzc8PXX38NV1dXhIeHo1GjRkhMTMSTTz6p6QR96dIlZGZm4vHHH7fiJzNOq1atsH79egwePBgKhQKzZs2qUKPUrFkz7Nq1C8OHD4dKpYK/vz9eeOEF3HPPPXj99dcxbNgw7Nu3D//973/x4Ycf1ro8Q4YMwfjx4/Hxxx/D09MTL730Eho3bqxpcpsyZQoSEhLQunVrZGdn47fffkPbO4NzZs+ejejoaLRv3x7FxcXYuHGj5jlLYQ2QPWMTGBHZsXfeeQe9evXC4MGDERcXh/vuuw/R0dGVnu/j44NPP/0UPXv2RMeOHbF9+3b89NNPaNSoEQDgo48+wqOPPopnn30Wbdq0wfjx46tcnNuWFi1aBF9fX/To0QODBw9GfHw8unbtqnfOvHnzcPHiRbRo0UIzH1LXrl2xdu1arF69Gh06dMDs2bMxb948vRFgNfXFF18gOjoaDz74IGJjYyFJEjZv3qxpyisvL8fEiRPRtm1bDBw4EK1bt9YEL2dnZ8ycORMdO3ZE7969oVQqLT4xcp1aDLWusJvFUN95B5gxQ+zHxQHbttm2PERU53AxVKpv7HIxVDKzmze1+6wBIiIi0mAAsme6S4bU0WpcIiIiW2AAsmd3ZtYGwABERESkgwHInukGIDaBERERaTAA2TPWABERERnEAGSv1GpAd5r1W7fEMSIiImIAslvZ2YDuDKCSBFh6ZV0iIqJ6ggHIXskjwHx8tMfYDEZERASAAch+yc1fwcHa5ZXZEZqIqEEZM2YMhg4dauti1EkMQPZKrgEKDAQ8PMQ+a4CIiOqUvn37YsqUKbYuRoPEAGSv5AAUFAS4u4t9BiAiIqsoLS216vuVlJRY9f3sAQOQvZKbwHRrgNgERkR2JD8/HyNHjoS7uztCQkKwePHiCjUqxcXFmDZtGho3bgx3d3fExMRgx44dmudXrFgBHx8f/Pzzz2jbti08PDwwcOBApKWl6b3XZ599hrZt28LFxQVt2rTRWz394sWLUCgUWLNmDfr06QMXFxesWrUKN27cwIgRI9C4cWO4ubkhKioK3377reZ1Y8aMwc6dO/Hee+9BoVBAoVDg4sWLAICdO3eie/fuUKlUCAkJwUsvvYSysjLNa/v27YtJkyZhypQp8Pf3R3x8vFH3rLi4GM899xwCAwPh4uKC++67DwcPHtQ8n52djZEjRyIgIACurq5o1aoVvvjiCwAiZE2aNAkhISFwcXFBeHg45s+fb9T71kWOti4AWQhrgIiopiRJTJ1hC25ugEJh1KlTp07Fnj178OOPPyIoKAizZ8/GkSNH0LlzZ805kyZNwsmTJ7F69WqEhobi+++/x8CBA3H8+HG0atUKAHDr1i0sXLgQX331FRwcHPDEE09g2rRpWLVqFQBg1apVmD17Nv773/+iS5cuOHr0KMaPHw93d3ckJiZq3uull17Cu+++iy5dusDFxQW3b99GdHQ0XnzxRXh5eWHTpk0YNWoUWrRoge7du+O9997D6dOn0aFDB8ybNw8AEBAQgKtXr+KBBx7AmDFj8OWXX+LUqVMYP348XFxcMHfuXM37rVy5EhMmTMCePXuMvr0zZszAunXrsHLlSoSHh2PBggWIj4/H2bNn4efnh1mzZuHkyZPYsmUL/P39cfbsWRTdGUH8/vvv48cff8TatWvRtGlTpKamIjU11ej3rnMkqiA3N1cCIOXm5tq6KDX30EOSBEjSsmWS1K+f2P/6a1uXiojqmKKiIunkyZNSUVGR9mBBgfiZYYtHQYFR5c7Ly5OcnJyk7777TnMsJydHcnNzkyZPnixJkiRdunRJUiqV0tWrV/Ve269fP2nmzJmSJEnSF198IQGQzp49q3l+6dKlUlBQkObrFi1aSN98843eNV5//XUpNjZWkiRJunDhggRAWrJkSbXlHjRokPTCCy9ovu7Tp4+mvLKXX35ZioyMlNRqtV6ZPDw8pPLycs3runTpUu37JSYmSkOGDJEkSZIKCgokJycnadWqVZrnS0pKpNDQUGnBggWSJEnS4MGDpbFjxxq81r///W/pH//4h165bMHgv9k7TPn9zRoge6VbA8QmMCKyM+fPn0dpaSm6d++uOebt7Y3IyEjN18ePH0d5eTlat26t99ri4mI0atRI87WbmxtatGih+TokJASZd7oRFBYW4ty5cxg3bhzGjx+vOaesrAze3t561+3WrZve1+Xl5XjzzTexdu1aXL16FSUlJSguLoabPDK3En///TdiY2Oh0KkJ69mzJwoKCnDlyhU0bdoUABAdHV3lde527tw5lJaWomfPnppjTk5O6N69O/7++28AwIQJE/DII4/gyJEjGDBgAIYOHYoePXoAEE12/fv3R2RkJAYOHIgHH3wQAwYMMKkMdQkDkL3SHQUm/0e/ccN25SGi+sPNzXZ/MFUTDkxRUFAApVKJw4cPQ6lU6j3nIf9hCBECdCkUCkiSpLkGAHz66aeIiYnRO+/ua7rL3Q3ueOedd/Dee+9hyZIliIqKgru7O6ZMmWK2Dst3v585JCQk4NKlS9i8eTO2bduGfv36YeLEiVi4cCG6du2KCxcuYMuWLdi+fTsef/xxxMXF4X//+5/Zy2ENDED2Su4EHRQEBASI/aws25WHiOoPhULbd7COat68OZycnHDw4EFNjUhubi5Onz6N3r17AwC6dOmC8vJyZGZmolevXjV6n6CgIISGhuL8+fMYOXKkSa/ds2cPhgwZgieeeAIAoFarcfr0abRr105zjrOzM8p1Z+0H0LZtW6xbtw6SJGlqgfbs2QNPT080adKkRp8DAFq0aAFnZ2fs2bMH4eHhAMRotYMHD+p1HA8ICEBiYiISExPRq1cvTJ8+HQsXLgQAeHl5YdiwYRg2bBgeffRRDBw4EDdv3oSfn1+Ny2UrDED2qKBA24ExMJABiIjsjqenJxITEzF9+nT4+fkhMDAQc+bMgYODgyY0tG7dGiNHjsTo0aM1nZOzsrKQlJSEjh07YtCgQUa912uvvYbnnnsO3t7eGDhwIIqLi3Ho0CFkZ2dj6tSplb6uVatW+N///oe9e/fC19cXixYtQkZGhl4AatasGfbv34+LFy/Cw8MDfn5+ePbZZ7FkyRL8+9//xqRJk5CSkoI5c+Zg6tSpcHCo+eBtd3d3TJgwQXPPmjZtigULFuDWrVsYN24cAGD27NmIjo5G+/btUVxcjI0bN6Jt27YAgEWLFiEkJARdunSBg4MDvvvuOwQHB8NHd8WBeoQByB7JtT+urqL/DwMQEdmhRYsW4ZlnnsGDDz4ILy8vzJgxA6mpqXBxcdGc88UXX+A///kPXnjhBVy9ehX+/v6499578eCDDxr9Pk899RTc3NzwzjvvYPr06XB3d0dUVFS1Exi++uqrOH/+POLj4+Hm5oann34aQ4cORW5uruacadOmITExEe3atUNRUREuXLiAZs2aYfPmzZg+fTo6deoEPz8/jBs3Dq+++qrJ9+hub731FtRqNUaNGoX8/Hx069YNP//8M3x9fQGIGqmZM2fi4sWLcHV1Ra9evbB69WoAInQuWLAAZ86cgVKpxD333IPNmzfXKpTZkkKSGzpJIy8vD97e3sjNzYWXl5eti2O6ffuAHj2A8HDg4kVgyxbggQeALl2AI0dsXToiqkNu376NCxcuICIiQi841EeFhYVo3Lgx3n33XU2NBtmfqv7NmvL7mzVA9kju7OzvL7aNG4vthQtioKmRc2wQEdVlR48exalTp9C9e3fk5uZq5tIZMmSIjUtG9QEDkD2S+//InRhbtwYcHICcHCAtDQgNtVnRiIjMaeHChUhJSYGzszOio6Px+++/w1/+44+oCgxA9ujOrJ1wdRVbFxegZUvg9Gng5EkGICKyC126dMHhw4dtXQyqp+pnzyWqmhyAdOfTCAwU25wcqxeHiIiormEAskdyE5hcAwQAKpXYcsVgIjKA42GovjDXv1UGIHt0dxMYADg7i21xsfXLQ0R1ljwL8i1bLX5KZCL53+rdM3ibin2A7JGhACTXADEAEZEOpVIJHx8fzdpXbm5uemtQEdUVkiTh1q1byMzMhI+PT4WlSEzFAGSPDPUBYhMYEVUiODgYADQhiKgu8/Hx0fybrQ0GIHtkqA8Qm8CIqBIKhQIhISEIDAxEaWmprYtDVCknJ6da1/zIbBqAdu3ahXfeeQeHDx9GWloavv/+ewwdOrTS88eMGYOVK1dWON6uXTv89ddfAIC5c+fitdde03s+MjISp06dMmvZ67SqmsBYA0RElVAqlWb75UJU19m0E3RhYSE6deqEpUuXGnX+e++9h7S0NM0jNTUVfn5+eOyxx/TOa9++vd55u3fvtkTx6y72ASIiIqqSTWuAEhISkJCQYPT53t7e8Pb21ny9YcMGZGdnY+zYsXrnOTo6mqV9sN4y1AeITWBEREQa9XoY/Oeff464uDiEh4frHT9z5gxCQ0PRvHlzjBw5EpcvX67yOsXFxcjLy9N71GucB4iIiKhK9TYAXbt2DVu2bMFTTz2ldzwmJgYrVqzA1q1b8dFHH+HChQvo1asX8vPzK73W/PnzNbVL3t7eCAsLs3TxLYtNYERERFWqtwFo5cqV8PHxqdBpOiEhAY899hg6duyI+Ph4bN68GTk5OVi7dm2l15o5cyZyc3M1j9TUVAuX3sI4ESIREVGV6uUweEmSsHz5cowaNQrO8i/2Svj4+KB169Y4e/ZspeeoVCqo5BoSe8B5gIiIiKpUL2uAdu7cibNnz2LcuHHVnltQUIBz584hJCTECiWrI9gERkREVCWbBqCCggIkJycjOTkZAHDhwgUkJydrOi3PnDkTo0ePrvC6zz//HDExMejQoUOF56ZNm4adO3fi4sWL2Lt3L/75z39CqVRixIgRFv0sdUpVEyGyBoiIiMi2TWCHDh3C/fffr/l66tSpAIDExESsWLECaWlpFUZw5ebmYt26dXjvvfcMXvPKlSsYMWIEbty4gYCAANx33334448/EBAQYLkPUtewBoiIiKhKNg1Affv2rXJZ+xUrVlQ45u3tXeWqxatXrzZH0eo3BiAiIqIq1cs+QFSF0lKgvFzs63aCdnER29u3rV8mIiKiOoYByN7o1o7p1gDJYaiw0LrlISIiqoMYgOyN3PylUGibvQDA3V1sGYCIiIgYgOyOHIBcXEQIkskBqIr+U0RERA0FA5C9MTQJIsAaICIiIh0MQPbG0BxAgH4AqmLkHRERUUPAAGRvDA2BB7Q1QuXlnAyRiIgaPAYge1NZAJJrgAA2gxERUYPHAGRvKusD5OQkHgADEBERNXgMQPamshoggCPBiIiI7mAAsjeVdYIGOBKMiIjoDgYge1NVDRBngyYiIgLAAGR/KusDBLAGiIiI6A4GIHtjTB8gBiAiImrgGIDsjTF9gNgJmoiIGjgGIHvDGiAiIqJqMQDZm6r6ALETNBEREQAGIPvDGiAiIqJqMQDZm+JisVWpKj7HAERERASAAcj+yAudOjtXfI6doImIiAAwANmf0lKxldf90sUaICIiIgAMQPanqhogdoImIiICwABkf+QaoKqawBiAiIiogWMAsjdyDRCbwIiIiCrFAGRvjKkBYidoIiJq4BiA7A1rgIiIiKrFAGRv2AmaiIioWgxA9obD4ImIiKrFAGRvjJkIkQGIiIgaOAYge2NMDdCtW4Babb0yERER1TEMQPbGmBogALh92zrlISIiqoMYgOxNVcPgdVeIZzMYERE1YAxA9qaqYfBKJeDiIvYZgIiIqAFjALI3VTWBAewITUREBBsHoF27dmHw4MEIDQ2FQqHAhg0bqjx/x44dUCgUFR7p6el65y1duhTNmjWDi4sLYmJicODAAQt+ijqkvFzbudlQDRDAAERERAQbB6DCwkJ06tQJS5cuNel1KSkpSEtL0zwCAwM1z61ZswZTp07FnDlzcOTIEXTq1Anx8fHIzMw0d/Et6tQp4OJFE18k9/8Bqq8B4nIYRETUgDna8s0TEhKQkJBg8usCAwPh4+Nj8LlFixZh/PjxGDt2LABg2bJl2LRpE5YvX46XXnqpNsW1mhs3gLZtxb5aDSgURr5QNwBVVgPE2aCJiIjqZx+gzp07IyQkBP3798eePXs0x0tKSnD48GHExcVpjjk4OCAuLg779u2r9HrFxcXIy8vTe9jS4cPa/bIyE14o9/8B2AeIiIioCvUqAIWEhGDZsmVYt24d1q1bh7CwMPTt2xdHjhwBAFy/fh3l5eUICgrSe11QUFCFfkK65s+fD29vb80jLCzMop+jOleuaPdNmq5HDkAKhRjxZQgDEBERkW2bwEwVGRmJyMhIzdc9evTAuXPnsHjxYnz11Vc1vu7MmTMxdepUzdd5eXk2DUG6Aai4GPD0NPKFBQVi6+FR+TkMQERERPUrABnSvXt37N69GwDg7+8PpVKJjIwMvXMyMjIQHBxc6TVUKhVUKpVFy2mK/fu1+ybVAMkBqKrExE7QRERE9asJzJDk5GSEhIQAAJydnREdHY2kpCTN82q1GklJSYiNjbVVEU0iScDvv2u/NikA5eeLbVU1QOwETUREZNsaoIKCApw9e1bz9YULF5CcnAw/Pz80bdoUM2fOxNWrV/Hll18CAJYsWYKIiAi0b98et2/fxmeffYZff/0Vv/zyi+YaU6dORWJiIrp164bu3btjyZIlKCws1IwKq+vy8rQ5BhBNYEYzpQaIAYiIiBowmwagQ4cO4f7779d8LffDSUxMxIoVK5CWlobLly9rni8pKcELL7yAq1evws3NDR07dsT27dv1rjFs2DBkZWVh9uzZSE9PR+fOnbF169YKHaPrqrunKzJ7DRADEBERkW0DUN++fSFJUqXPr1ixQu/rGTNmYMaMGdVed9KkSZg0aVJti2d1+/cD996rf8xifYAYgIiIqAGr932A7MnLL1c8dt99JswIbUoNEDtBExFRA8YAVIdkZRk+bvQE1qwBIiIiMgoDUB1SWYfn1FQjL8BRYEREREZhAKpD5AC0Zw/Qq5f2uNGtVawBIiIiMgoDUB0iByB3d7Egqqy83MgLcBQYERGRURiA6hB5xJdKBZw8qT2uu8ZplVgDREREZBQGoDpErgFycQEiIrTHjR4Kz1FgRERERmEAqkPkAKRSAWvWAJ06ia+NDkDG1ACxEzQREREDUF1RVgao1WJfpQLuuQf47jvxtVlrgLy8xLa4GNBZhoSIiKghYQCqI3RDjrwwvYtLxeeqZEwNkK8v0LOn2N+wQXs8NRX473+1NUNGdzwiIiKqfxiA6gjdOYDuDkDFxWKV+GoZUwMEAB076p8PAPffD/z732LWxZ9+Em++fLlRZSciIqpvGIDqCDkAKZWA450V2uQApPt8lYypAQIAV1ex1a1aOndObNetAx56SCSuceOMeFMiIqL6hwGojtDtAC3TDUDVNoOVlWmbreSOzpWRA1BRUcXnDB0jIiKyMwxAdURGhtg6O2uPOToCDne+Q9UGIN0T5IBTGTlZGQo7OTnVvJEN3L4NfPghcP68rUtCRER2ggGojnjkEbHVzR8KhQkdoXXDjG7VkSF3N4FlZxtbTNt44w1g4kQgKsrWJSEiIjvBAFRHXLtm+LjRAUg+wdlZW21UmbubwB54wKgy2sy2bWLLyRuJiMhMGIDqOJNrgKpr/tK9qPyaP/6oUdmsxqghcERERMZjAKojmjcX2xEj9I/LNUP/+U81F5ATUnXNX4B+E1hpqf5z4eHVv97a5BkiiYiIzIQBqI6Qf8dPnmz4ed05Cw0ypQZItwns7k7PbdpU/3prOHwYiIsTWwYgIiIyMwagOkKegFleq1Q2c6bYdu5czQXkAGRMDZBuE9jdAahFi+pfbw0PPwwkJQHdumnnNyIiIjITBqA6orIA1K+f2BrdCdqUGqDMTGDvXu3xTZuAJk2qf701XL6s3T992nblICIiu+Ro6wKQaOGRBzjdvYqFPKlztZUgptQAyQHo2jVgzBix37GjGA3m7a09z8mp+mtZSqNGwI0btnt/IiKya6wBqgN0R3ffXQMkByLdZbsMqkkNkC5fX7Ht2RN4/339Y7YQHGy79yYiIrvHAFQHyM1fCkXFbGKRGqCIiIpzBfn4aPcHDBBboxYgsxDdKbF1cUg8ERGZAQNQHSDX7ri5iRCkS64BKinRLvVlkCk1QB4eFYe767a96S5DbyuVLclx97B9IiKiGmAAqgMuXRLb0NCKz+nmkiprgUypAQKAli31v37lFe2+vCJrcbHtalxycw0fr7Y3OBERUfUYgOqAU6fEtm3bis85OWnzSJX9gOSORHd3IqpMnz76Xzdtqt2X31CSxCrz1qZWMwAREZFFMQDVASkpYhsZafh5eWBWZZkAgLYjkZubcW/6wgv6X+u+TrcZzdCK8ZaWkwOUlxt+zhblISIiu8MAVAfIU95ERBh+3s9PbKscFW5qDZCLi5hsUKbb+Uil0g6BrzJ1WUhWlth6eQHHjonV4OXe4NUOhyMiIqoeA1AdcPWq2DZubPj5Ro3EtsoAZGoNEFB585ZCYWS1k4XIASggQMxP9PLL2k7b8uJoREREtcAAVAcYG4Bu3qziIqbWAAFV9++RA1Blo7EsSTcAyeSbI98sIiKiWmAAsrGyMiAjQ+xXFoCMagKrSQ1QVUPm5XmBbFED9NFHYqsbgOQlOq5csX55iIjI7jAA2Vhennaxc39/w+cY1QRWkxqgBQvEcPilSys+Z8smsD//FFvdeQHkdMgmMCIiMgOuBWZjcm5xdgYcK/luyDVA2dlVXKiy1VSr0rw5cOaM4edsGYDkDzpzpvaYvCyHLZrkiIjI7ti0BmjXrl0YPHgwQkNDoVAosGHDhirPX79+Pfr374+AgAB4eXkhNjYWP//8s945c+fOhUKh0Hu0adPGgp+iduQAVFVrlJxp5IxjUE2awKpiqz5At29rp7zWXZ5DLk9ennXLQ0REdsmmAaiwsBCdOnXCUkNNMAbs2rUL/fv3x+bNm3H48GHcf//9GDx4MI4ePap3Xvv27ZGWlqZ57N692xLFNws5AFWVW4wKQDVpAquKPAW17kqt1iDXOCkU2qHvgBgSDzAAERGRWdi0CSwhIQEJCQlGn79kyRK9r99880388MMP+Omnn9ClSxfNcUdHRwTXk9XEzRaAzF0DJC+pYe2Zl+UA5Ompv2CrHIBs0SRHRER2p153glar1cjPz4ef3EnmjjNnziA0NBTNmzfHyJEjcVmeabASxcXFyMvL03tYizyxcZ2rAbJ1AJKbvGTy1/LCaURERLVQrwPQwoULUVBQgMcff1xzLCYmBitWrMDWrVvx0Ucf4cKFC+jVqxfyq5hBeP78+fD29tY8wsLCrFF8AGbqAyRJlqsBsvaK8JUFIN0msDVrrFsmIiKyO/U2AH3zzTd47bXXsHbtWgQGBmqOJyQk4LHHHkPHjh0RHx+PzZs3IycnB2vXrq30WjNnzkRubq7mkZqaao2PAMBMTWClpdq1s+y1BkgOQAAwbZr1ykNERHapXg6DX716NZ566il89913iIuLq/JcHx8ftG7dGmfPnq30HJVKBZW8ArqVmSUA6T5hrgAk3w9rB6DKhvPrjgjTnSCRiIioBupdDdC3336LsWPH4ttvv8WgQYOqPb+goADnzp1DSEiIFUpnOrP0AZKfcHTULmJaW7aqAZKb3OT3l7m5Aa1aiX15ZkgiIqIasmkAKigoQHJyMpKTkwEAFy5cQHJysqbT8syZMzF69GjN+d988w1Gjx6Nd999FzExMUhPT0d6ejpydUYGTZs2DTt37sTFixexd+9e/POf/4RSqcSIESOs+tmMZUwfIDkc3bqlnTXa4EXMVfsD2C4Aye9nqEbugw/EVl4rjIiIqIZsGoAOHTqELl26aIawT506FV26dMHs2bMBAGlpaXojuD755BOUlZVh4sSJCAkJ0TwmT56sOefKlSsYMWIEIiMj8fjjj6NRo0b4448/EFBHm03keQaN6QQNaGuM9Ji7AzRQ92qAAEDu65WZab3yEBGRXbJpH6C+fftCkqRKn1+xYoXe1zt27Kj2mqtXr65lqazrf/8T265dKz9HN9fcumWgoqeh1ADJi6VlZYmRbwqF9cpFRER2pd71AbInkgScPi32H3yw8vOUSm0eMdgPyB5rgAwFIHk9sLKyaiZFIiIiqhoDkA0VFooQBGh/t1emyo7QlqwBsvY8QFU1gbm7a1eM5aKoRERUCwxANiT33VYqq+4DBFQTgOypBqiqJjCFQpsYhw2zXpmIiMjuMADZkLzihpdX9d1ZqgxAcmioLkWZwtZNYIZqgADthI9791qnPEREZJcYgGyoskmPDakyAFXVb6am5GsZHHZmIX/8AXzyif77ExERWQADkA3p1gBVx6gaoMpqTWpCDiClpea7ZnViYyu+PxERkQUwANmQ2WqALBGAnJ3FtqTEfNc0RWWfZeZM7b7cHEZERGQiBiAbMlsNUHX9ZmpCDkBqtW2CRmU1QK++qt2XR78RERGZiAHIhgoKxNbTs/pzjaoBMmezkRyAANvUAlX2WVxdtT3GORcQERHVEAOQDRmzErzM6k1guouq2qoZzBCFQn9xNCIiohpgALIhUwJQlb/z7SUA6bYFOlaxSkuVaZCIiKh6ZglAOZyVt0bMVgNkiWHwDg7aEGKNACRJ2g/3r38BDz1U+bkMQEREVEsmB6C3334ba9as0Xwtr7jeuHFjHDt2zKyFs3d1ugkMsN5IMEkCHn1U29n6ww+rDnMMQEREVEsmB6Bly5YhLCwMALBt2zZs27YNW7ZsQUJCAqZPn272AtozBqA7bt4E1q/Xfl3dmmYMQEREVEtVdLQwLD09XROANm7ciMcffxwDBgxAs2bNEBMTY/YC2jMGoDvu7thUVf8fQNtXSJ5HgIiIyEQm1wD5+voiNTUVALB161bExcUBACRJQjknpjNJne4DBFgvAOl+KGNmhZTPYd8zIiKqIZNrgB5++GH861//QqtWrXDjxg0kJCQAAI4ePYqWLVuavYD2jDVAd+jWAB0+XP35cgCSp9ImIiIykckBaPHixWjWrBlSU1OxYMECeHh4AADS0tLw7LPPmr2A9sxsAUhesLS+BiD5Q7VuDbRoUf35DEBERFRLJgcgJycnTJs2rcLx559/3iwFakjMFoBMmVLaFPJcQNu3A336mPfauuQPZcyNABiAiIio1owKQD/++CMSEhLg5OSEH3/8scpzH6pq/hbSY7YAlJ8vtndq48zm+HGx/c9/gNdfN++1dck3orrRXzL2ASIioloyKgANHToU6enpCAwMxNChQys9T6FQsCO0CUz5vW9UADJ3DZC1sAaIiIiszKgApFarDe5T7ZhSAyRX7pSViS45mrVKy8q0fYDqawAytQYoNFRs//pLTKIoL45KRERkJLOuBXaLi1MaTXflB1OawABtlx8A+lVC9TUAmVoD1Lu3uCFXrogQREREZCKTA1C/fv1w9erVCsf379+Pzp07m6NMDUJpqXblB2N+7zs5aWt99JrB5OYvR0edaqF6xtQaIBcX7WixtDTLlImIiOyayQHIxcUFHTt21KwHplarMXfuXPTq1QsPPPCA2Qtor3Qry4yt+JCbwfRqgHT7/5i7KWjePO1+WZl5r61L/kDGBiAA8PMT248/Nn95iIjI7pk8DH7Tpk1YunQpnnzySfzwww+4ePEiLl26hI0bN2LAgAGWKKNdkgOQUqkdbV4dd3exbFalAcjcXngBmD1b7N++bf5RZjK5M7Mxs0DLfHzEdt064NIlIDzc7MUiIiL7ZXIAAoCJEyfiypUrePvtt+Ho6IgdO3agR48e5i6bXdPtAG1sxY2cP/SawOQvLBFOdCdWrGsBSHdyxsxMBiAiIjKJyU1g2dnZeOSRR/DRRx/h448/1iyG+uGHH1qifHbLlBFgMoNNYJZaBgMAHBy0/Yrk97GEmgQg3YVQOR8QERGZyOQaoA4dOiAiIgJHjx5FREQExo8fjzVr1uDZZ5/Fpk2bsGnTJkuU0+7UJAAZnAtIDibmXghV5uIialvkofaWUNsAdOOGectDRER2z+QaoGeeeQa7du1CRESE5tiwYcNw7NgxlFh6zSg7UpsaILnbDwDLrQQvk2uW6loN0JtvavcZgIiIyEQmB6BZs2bBwaHiy5o0aYJt27aZpVANQU0CkJeX2OpWflg8ALm6im1dC0CDBokHAFy/bv4yERGRXatRJ2hATHp4+fLlCrU+HTt2rHWhGoKaBKBGjcRWr8JDDkCW6AOke11LNoHJic6UAAQAHTsCmzaJoXFEREQmMDkAZWVlYezYsdiyZYvB57kWmHFMnfsP0E59o/f7vr43gUlSzQOQwSoxIiKi6pncBDZlyhTk5ORg//79cHV1xdatW7Fy5Uq0atWq2pXiScvsNUCWCkByyMjOtsz1CwtFCNJ9L2PJ5+t1iiIiIqqeyTVAv/76K3744Qd069YNDg4OCA8PR//+/eHl5YX58+djkNwvg6pUkwBksAbI0qPAwsLENjXVMteXa2+UStOb8eTJHxmAiIjIRCbXABUWFiIwMBAA4Ovri6ysLABAVFQUjhw5YtK1du3ahcGDByM0NBQKhQIbNmyo9jU7duxA165doVKp0LJlS6xYsaLCOUuXLkWzZs3g4uKCmJgYHDhwwKRyWUNtApBVa4CaNhXby5ctc305AHl5mb6UhxyA2ARGREQmMjkARUZGIiUlBQDQqVMnfPzxx7h69SqWLVuGkJAQk65VWFiITp06YenSpUadf+HCBQwaNAj3338/kpOTMWXKFDz11FP4+eefNeesWbMGU6dOxZw5c3DkyBF06tQJ8fHxyMzMNKlsllaTAOTrK7Z6rVGWDkDyDMuXLlnm+roByFSsASIiohoyuQls8uTJSLuzAvecOXMwcOBArFq1Cs7OzgZrY6qSkJCAhIQEo89ftmwZIiIi8O677wIA2rZti927d2Px4sWIj48HACxatAjjx4/H2LFjNa/ZtGkTli9fjpdeesngdYuLi1EsBwkAeVaoUajNRIi6C6lafBRYQIDYWmqkFQMQERHZgMk1QE888QTGjBkDAIiOjsalS5dw8OBBpKamYtiwYeYun559+/YhLi5O71h8fDz27dsHACgpKcHhw4f1znFwcEBcXJzmHEPmz58Pb29vzSNM7vdiQfJszrWeCdrSNUDydXUColnVJgDJr7l8Gbh61XxlIiIiu2dyANK1Z88eKJVKdO3aFf7+/uYqU6XS09MRFBSkdywoKAh5eXkoKirC9evXUV5ebvCc9PT0Sq87c+ZM5Obmah6plurwq6O2NUBq9Z2Dlu4EXZcDkFwDBABz5pinPERE1CDUKgAlJCTgqh385a1SqeDl5aX3sLTaBCBAZ17C+l4DJDdf1eSey81zAHDihHnKQ0REDUKtApAkz99iJcHBwcjIyNA7lpGRAS8vL7i6usLf3x9KpdLgOcHBwdYsarVqEoDkVSl0X1/vA1BtaoCcnYEffhD7Vqi1IyIi+1GrAGRtsbGxSEpK0ju2bds2xMbGAgCcnZ0RHR2td45arUZSUpLmnLpCHsml24pTHd2pcjT9gAoKxFY3HZlTXQ5AgFgOA+ByGEREZBKTA1BiYiJ27doFAPj4448r9LcxRUFBAZKTk5GcnAxADHNPTk7G5TtzzsycOROjR4/WnP/MM8/g/PnzmDFjBk6dOoUPP/wQa9euxfPPP685Z+rUqfj000+xcuVK/P3335gwYQIKCws1o8LqAkkCzp4V+82bm/baCh2hT50S25YtzVK2Cup6AJJfd/s2UFpqnjIREZHdM3kYfG5uLuLi4hAeHo4xY8YgJycH7qYsaKXj0KFDuP/++zVfT506FYAIWStWrEBaWpomDAFAREQENm3ahOeffx7vvfcemjRpgs8++0wzBB4Ahg0bhqysLMyePRvp6eno3Lkztm7dWqugZm7Xr4sF0BUKoEUL017r7i4mQiwshAgPctNP+/ZmLyeAuh+AdKvQ8vO1s0USERFVQSHVoCNPVlYWvvrqK6xcuRInT55EXFwcxo0bhyFDhsDJyckS5bSqvLw8eHt7Izc31yIdog8eBLp3Bxo3Bq5cMe217doBf/8N/PYb0DfgL6BDB/FLX296aDO6ehVo0gRwdLRMDcvgwcDGjcBnnwHjxtXsGi4uIqBdvKiduJGIiBocU35/16gPUEBAAKZOnYpjx45h//79aNmyJUaNGoXQ0FA8//zzOHPmTI0K3lDIlR7yzM6mkDtNFxZC2xPalI5EpnJ2FtuyMp2x92ZU2xogXa+/XvtrEBFRg1CrTtBpaWnYtm0btm3bBqVSiQceeADHjx9Hu3btsHjxYnOV0e7I/ZY9PEx/rV4foJoMJTOV7ugySzSDmSMAyeX6/PPal4eIiBoEkwNQaWkp1q1bhwcffBDh4eH47rvvMGXKFFy7dg0rV67E9u3bsXbtWsybN88S5bULZg9AlhoBBlg+AMmjt7y9zXM9K0/NQERE9ZPJnaBDQkKgVqsxYsQIHDhwAJ07d65wzv333w8fHx8zFM8+mSMA3boF69QAyU1ggPkDUFGRthO3qcPhKpObC/DfHhERVcPkGqDFixfj2rVrWLp0qcHwAwA+Pj64cOFCbctmt2oTgAz2AbJkAFIotPuVLCZbY2fPihobHx/9WZ1N1amTdv/atVoXi4iI7J/JAWjUqFFwsdTK4w1EveoDpGvFCvNe79w5sW3VSj9omeqXX7T7aWm1KxMRETUI9WomaHtRr5rALEnu/1Ob2h8ACAwEevcW+5aaDoCIiOwKA5AN1NsaIHOT1wOpyXwAd5MnQOSSGEREZAQGIBuodwFo0CCx7dnTvNfNyRFbc3RaZgAiIiITMADZQL3qBA0ATz8ttuaeCZo1QEREZCMMQDZg9j5AlpwHCNAuQW/uYfCsASIiIhthALIBszWByRey5FIYgOUWRGUNEBER2QgDkA2YLQCZcx2tqlgqAJmzBigoSGx/+EF7XSIiokowANmA2foA2UsAMkcNUIsW2v1nn6399YiIyK4xANmA2foAWTsA3b5t3uvKTWDmqAHSXUrj229rfz0iIrJrJq8FRrVntiYwRysFIEt3gjZHDZB8Y4iIiIzAGiArKyvTVqTUOgDl5oov6mMTWHGxWAwVMN/ipUlJYuviwlXhiYioSgxAVlZYqN2vTQC6fVuCZO0msLIyQK02zzXl2h+Fwnzlv+8+cb3bt4GMDPNck4iI7BIDkJXJzV+OjoCzs+mvlztBq1AMhTwxobUCEGC+WiDd/j8OZvpn6Oys7Qz911/muSYREdklBiAr0+3/U5MF0F1dxevccEt70NIzQesGIHN1hDZnB2hdHTqI7YkT5r0uERHZFQYgK6tNB2jgTvhxAxxRpj3oaOG+7E5O2rRmrhoguYlKnr/HXNq0EduzZ817XSIisisMQFZW2wAEiH5ATrjT/OXoWLOqJFMoFObvCJ2eLrbmDkCNG4vttWvmvS4REdkVBiArM3sAcnKqfaGMYe4AZKkaIDkAXb1q3usSEZFdYQCyMnMEIF9fnSYwSzd/yepLDVBoqNiyBoiIiKrAAGRl5ghAfn42rAEyVyfozEyxNXcAatJEbK9dA0pKzHttIiKyGwxAVmauGiCrB6AqZoPOza1BxZC8aru8iru5hIaKm1teDnz8sXmvTUREdoMByMrMVQNUV5rALl4EwsJEPrp0yYTrycPgzbEMhi6FAlAqxf5zz5n32kREZDcYgKys3jeB3RWAPvoIyM8X+/HxJlzPUgEIAJ5/XrvPZjAiIjKAAcjK6m0TmIEAlJUFLFigPSUlBVi8WJttqmTJADR7tnaabXaGJiIiAxiArMwcAcjHx4ZNYDqdoP/974qnTZ0qaqjkpb4MKivTVhtZIgApFEDTpmL/8mXzX5+IiOo9BiArq7fzABnoBP2//1V++mefVXEt3XRk7qUwZAxARERUBQYgKzNHAPLwqBudoO+9V/v0M8/onz57tnakewW5uWLr5ma5ABcWJrapqZa5PhER1WsMQFZmrgBUF/oAyZ9lyxbRGVqStF1uiorEFD8vvmjgWoWFYlubm1AduQbo5ZfNN3kjERHZDQYgK7OXALR9O3DsmDjk7689LSQEmD5d+/WCBcCePdpzAZjnJlSnUSPt/uefW+59iIioXqoTAWjp0qVo1qwZXFxcEBMTgwMHDlR6bt++faFQKCo8Bg0apDlnzJgxFZ4fOHCgNT5KtczVB8jWnaCfeEL7VECA/qlvvw1s3Kj9+r77gD59xNyEALQ1QO7ulikrAPTurd3futVy70NERPWSzQPQmjVrMHXqVMyZMwdHjhxBp06dEB8fj8xKOpCsX78eaWlpmseJEyegVCrx2GOP6Z03cOBAvfO+/fZba3ycatXbGiDZ7NmQ1BJu3NAekpffkikUQLdu+sdyc4Hz5+98YY0msC5dgLlzxb5uYYmIiFAHAtCiRYswfvx4jB07Fu3atcOyZcvg5uaG5cuXGzzfz88PwcHBmse2bdvg5uZWIQCpVCq983yrGG5dXFyMvLw8vYelmDsAqR2tFIDOndPs5l8vRtmdCqjcXMMZ7O5aIQBo3Ro4fBjam2DJGiBAVDsB2mU3iIiI7rBpACopKcHhw4cRFxenOebg4IC4uDjs27fPqGt8/vnnGD58ONzv+mW6Y8cOBAYGIjIyEhMmTMCNKmoB5s+fD29vb80jTB5BZGaSZJ7KD91RYOWwUhPYrFma3YyzYg4fLy/xMMShkn9ZL78M6zSBAdp1xm7e1Gl/IyIisnEAun79OsrLyxF014rgQUFBSE9Pr/b1Bw4cwIkTJ/DUU0/pHR84cCC+/PJLJCUl4e2338bOnTuRkJCA8kp+Cc6cORO5ubmaR6qFhk7nHUzBY9IaxOAPeHvX/DrOzoCLg6gBKlVYqQaob18xbB3A9QsiAN3d9HW3P/8ENmwAHnxQe6yoCNZpAgO0ASgzU/SV2rLFsu9HRET1hpWqDyzj888/R1RUFLp37653fPjw4Zr9qKgodOzYES1atMCOHTvQr1+/CtdRqVRQyZ18Lahk1XdYg1lY6fQUXFzurf4FlVAogEZepUAOcKvYEW7mK2LVPD2BW7dw85IIQCEhVZ8eFSUemzZpj924Aes1gd290vwPPwAJCZZ9TyIiqhdsWgPk7+8PpVKJjIwMveMZGRkIDg6u8rWFhYVYvXo1xo0bV+37NG/eHP7+/jh79mytyltbuZJoLwpU5db6WsH+ogks95YVO0F7egIAss6LABQRYdzL5szRDlY7eRK4ecVKNUCurvpfVzozIxERNTQ2DUDOzs6Ijo5GUlKS5pharUZSUhJiY2OrfO13332H4uJiPKE7HrsSV65cwY0bNxBSXZWFhd0oE+1efk6172Qd7C+awLILrR+AblwUAahlS+Ne1rixaPWKjhZfF5y7E0Rq0w5oDIUCmDFD+zWXxSAiojts3gQ2depUJCYmolu3bujevTuWLFmCwsJCjB07FgAwevRoNG7cGPPnz9d73eeff46hQ4eike6EdwAKCgrw2muv4ZFHHkFwcDDOnTuHGTNmoGXLloiPj7fa5zIkq1jUAPkqal8D5O0maoCKSqz4LbxTY5OTaloAAkS/JblSz/30EbHTsaM5S2fY228DI0aIYfGHDwPr1gFDhmiqpM6cAb77TjTnHTgALFsGxMYCrVoBaWlAixZiUult24CuXYEOHYDTp0Xr2gMPiJFtixaJeRcHDxbHHR0BtRrIyBCZUa7okiSRyYiIyPZsHoCGDRuGrKwszJ49G+np6ejcuTO2bt2q6Rh9+fJlONw1pCglJQW7d+/GL7/8UuF6SqUSf/75J1auXImcnByEhoZiwIABeP31163Sz6cqmcWixsMTta8BUt3pBF0sWb8GKO+a6MNjSgACxNIYjiiF77W/xIGuXc1ZuspFRorFXG/fBh59FBn/eh77hy3Chg3AF19UPH3fPvEARPCR/fab/nm6M17LQkKAe+4BfvxRfO3mJgJQZqaYSzImBrh1SxQpOFhcs1070VqnVIqwlZIi5lFq2xY4flzc9gEDgCtXRLhq3hwoKREj8FxcxIi76oKVWl35yDwiooZIIUmSZOtC1DV5eXnw9vZGbm4uvCob510D0qHDUNzTDeUhjaG8dqVW1zr6jxfQ5bdF+LH1NDyU8o6ZSliN4cOBNWswGUvwPiYjL0+TiYzy8svAZ/MzkYk7o/7KysRvfSuQhg+HYs0aAIAaCgQiEzfgX+Vr+vcH/v5b1AR5eoowo1TWvfVVfX1Fa2JhoaiBatoUuHRJ1G75+Igyl5YCbdoA2dli7qZOnUQe3LVL1M6VlIhr+fiIWq/yctFHPTxcrH5SViYmsvT1Fa8ZMUKEPV9f0dHdx0eEs4MHRUvjsGHiWFaWmELK1VUEt/JyMW/UtWuifB06iCbS1FQRHAsLxf3u1EmU2d1dlPPsWRGgAwP1P3tamqh9c3Kq47Vr5q7+kyTxTQ4OBn75RXTICwsT7+HlJbYZGUB+vvhGnTghqjXd3UUaP3sW2LlT/KMIDBRDOhs3FinZ2Vm8fs8ekda7dxfXzMwU19uwQXyz8/KAp54CcnLEN9vTU/yDkCTxj+zECfENdnXVziQPiG+oi4v57kV9UlYm/uqJiRH3q7RUrCvk7q79z1JcLKqX8/LEf8zjx8X97tlT/Gf780/x/fD1Ff+hW7USnSuVSvG9SE4G4uLEv40ffxTfs6NHgbVrgX79xPc8L088f+0a0KuXqMrOyhJlCg8XZW3SxJZ3qsZM+f1t8xqghkThLb4ZyoLa1wB53s4CAFx3CKzmTDO6k3Y8kY+gINPCDyB+LvpBTEp4S+UDNyuFn+JiIOH0MoTiQfwXk+CDXFxHAF7F63gDr+CnnxRISBC1JIWF4me5XGMiZzTd313l5eL5LVvEz5CAADG8/8YN8bPm3DnxdXi4eLz7rpiK6L77RFDZtUvU5ly+LH7mPP008PvvIgT07w98/33Fz6BQiPtnSHa2eADieikp+s/J9u/X7utWnsrhBxA/Pw8f1n69Z4/h96xuYvXFi6t+vjrBSIMfbuIk2usdb9lS3AcvKRdnLzkhv9wN3shBqPMNlAY2RqnSBS6OZYjK2I7fCrrBL9AJ4yN34ej1MNxyD0BE4Qk4oRTeOZdwLqgHeuf+hAIHL/zleS/8Tu3FRUUEGuMq0ou80Ly9GwrzyrHPeyD6NTuHztm/YV9qE2y8EYtmwbcxLP8zZDePxsWyxmhcdA5Dry1Fq+yDSAnvjwttB8E94xw8866h47n1cID45v0UOQ2dHf6EGg5QuLngdlYB8iQPnPWKxke+L+PV8tfQyeFPFLv5wfOPX+CTfwXXYh8BCgpQ1qET/PdvhmNRPhyLC+Bwsw7McP7660adJnl4QCGP/ryjvH1HXOg9Go6tWyCn12BcOlcGpZsKkZHi93JxsfgdHBkp/v/Iaw4qFBBPJiWJ0HbkiPiPlpEBPPKICHB3FBeL/w8XLoj/d8eOiWNXrojMoVSK3/2NG4um7ZAQ8Z5FReL5wEDx/6NjR/H//PZtQJ2WgRZpu6EsvoXbngHw/3UNHL9agYL2MVC1b4HSP/+GQ1kJoFLB5S/R3K/ucR+ka2lwSL0IhTFzks2ZY9R9NZmhHy4ffVTxmEIh2vSdncWNCAqC+tx5lLTqAEVuNsrKFShoFoXjzYcgX+mDW8VK+BRnoMzTFwVXclDeKBBOTuJeOzuL++bnJ35nHD4seiR0aZIF/7YGZsy1ItYAGWCpGiBkZoo/Y4Fa136kdRqIkD9/xtttV+DFk4lmKmA1pk4FFi/G25iBn3q+jd27TXv50aPAxK57sRc9cc21OUJvnav+RbV05AgwbZq2+epfWIVV0Ok4366d6Pxj6SH51ZAkEax0l3bLyBA/gHNzxT8VV2UJSorKUah2hZub+KFSVCT+QExPF3/USZL4IRMSIn7gXL4sQt2ZM+KHfMuW4ofSyZPAf/4jnnNwEIFOoQCefFI0v50/L35Q5eWJ16SnA6dOiZqWtNRSPI61mB70JWYGfI79V5ugo8MJQKnEzsw28EU2euF3nEIbtHO7BM+OESgpKsPvfzXCw+r/oVihQnloGA7eaIH4sk2IKDuN+9S7EIhMnEEr/I22SMRKqFCid49m4k14IQ/eyMWzED+0d6AP+mKn5pwLaIYIXLTGt4zMrBwOOIl2iMIJnENz5MAH0TiCEjjBWV76B0CaUxhCSiuvhv2rUW8cUvXE1sJe2Jh7HxSQkA/jf45H4xBCcQ3X4Y9s+CIahxGH7fgHfkUorkEBCUqoa/VZdd2EL1xwG24oMts1deWoguBTrD/SOi0gCjdcw9Dh8uZaXz8fHvCEfri9hhBcQjjUcMA5tEAkUtAc5xGA6wCA21DBBcVYNmQLntlg3nU6Tfn9zQBkgMUC0O3b2qHZ2dmiqqGGclp0hc/5o3ihzSa8+/cD5ilfdebMAebNw4eYgOTxH+KTT0y/xJF5G9F1zmAcc+6GTsUHzV9GHZIETVAAgM6dgTWrJbRe8TLw1lvaE/38RELQnTfo4EHRCcfSQ/WNJUligdczZ0S7nKGlXQw1sxw/LpKMv7/487d3b1ENdfmy+HzNm4vzvvhCVFX5+YnUM3y4CIYbNog/wYuKRPVQQABw9ar2pgKig5KB/nh1VU6j5vC5cb7qc1yD4VNU/WSsAKBWOMBBUqPQyRvupfoDHM47tUbz0tPac6HQ1AZV5lPXf8NDcQuhRWfRRZEML7W45mVFOE47tcfNcm9cLQ/CTlU84oo3YRL+ixRVFNIRjOsOQfhQ9TweL1qJNGUTeJTn4JJnFDqWHUGWa1NklPiimdNV/Br6BPKcGsEp4wq8pRw4ZlyF4vYt3BOZD/fMC7ji0BS3ih3g75QHH/VN5Cu8cNolCr75qfiscDhUgT6IztyM1xz/g5Wqp7G5sDdCkIYxWIlCuOME2uMaQnERzdAYV9EGp/A2XkQevBAM8cu4HA5mDRJV2YMeWOr8PCI6ecN/SE9k/JyMzBaxiOuvwIkTgNPFM3g4ZT4an98F/xzj/jC7AT+kIgxROA4l1NiCgUhFGIKQAV9lHlKkSISpLyIMqViLx7EPsciHJy4gAkPwA9rgFHagLzZhEFwg/j+VwgklUKEDjmM4VmM37sNWDIQTSuGC25iE/6IMjtiLHsiHJ7yQhya4gsOIhgQFbsENN9AIfbATaQjBCXSABAc4oByByMR1+KMMjgD0f054IRfeyEU6guGGW+iLHeiEY/BFNpxRgn/gV7RBCrajHzxQgEBkojku1Pr7cqr7KLTZ/2Wtr6OLAaiWLBaAJEn8KS9JovNCNXMdVeV2QBO4XL+Kka0PYlVKt+pfYA4LFwLTp+MrPIHri77C88+bfomc97+Ez+RE/IIB6HP7Z1iyX3p6uv5kjV99pbOK/alTIgDoGjxYdCiJigJeeEGc/NVX4jlJEgGibVuYXOhvvhHVOE8/LcKFbnjJyhIBRakU7WcPPijqjHfvFuEjNxe4914RyD7+WPu6bt1Evb6fHxAfL/pqbNokqo1atBDtcMHB4iZUx8dHhBtL0u1oVJmYGBHuCgtFU4a7u6g2DAoSvdKbNBFVZGVlogoLAAYOFH9U+PsDFy8Cjz2m7RWuUIjv34wZ4vu9dy+wYAHQrJl47YULokynTolAmJAAfPqp6NfSqpX4nv/vf6Ivy7Bh4v2dnESZbt8WfW5athTvk5NzZ42aO1V4paXiHE9PUbV3/bo41qSJfk6Vl+i5dUt8j1u0EB2g7paRoak9liRxC6y9DrL83llZomZS93OUlIhbIHcBkiQx32lBgXhOpRLfoqws8befk5P4yO3K/oR7Yx9xjwMCgIMHIS1ahKJOsXDpGY3SEykoyCmF1+7NcMpKAwAcGPw6rpUF4rhrdxQpPeDjAzQvO42MDv3gn3sOoSe3o+P+T+Cd+lf1H+jhh4H166v/3GOfhOLmDfHBJ05EfqNmuOXoBW8fBS5fFn9HpKeLb2fHjuK+lJeLz+vnJyr/MzLEPz1vb3F/iovFf3lnZ/FPIzdXvKawUNwrhULckuxs8c8nN1f8eAoJEfdUqRT/xJycxPWLirT9/hwdtc3hBQXiPbOyxB+EKpXoAlZ6p1KtqEh0IQsOFv8lXF21fwd16CDKEhAAqJwltI5UQJLEf828XAmqwpvwun4e2LhRFCQqSnRCPHRI29EvJES0YZ46BeTlQep5HxQd2iOnxA0YMwY+fuYdncEAVEsWC0CA+BdYVCR+WMudzWqgXOUKZclt9Is4j6TzRs5IWFsffww88ww2YAhctmzAwBrUXEpz5kIx7zV8i+EI/vVb3H+/+Yspmz1b20UhNVU0AelVkBw9CqxZI4bKV6Z9e/ET7fZt0X7epQswaRLwySfip9GgQcAHH4ifCB07ihBizISLAQHiB8Off9bqM5qN3AQYGys6ZQYHi5+AHh6iQ2VUlPip+OOP4jdd377ip+aJE+Kn87lz4qd7o0bil/6YMcAff4iOur17i8ePP4rnunTRduqQf1N4eGh/o3PIGhkipypjOx+mpYmfWevWiX+nxvLxEQH42WdFZ+OHHtJvm6Y6jQGoliwagHx9xS+QU6dE00JNSJLmF0R0aBoOX615TZIpyr9cBWXiE9iOfmh1cbvp+e3QITHUB8BbeBGFr75lbB9KkyUlid/bgPjDfnNVTd13gh08PLTLdNQVYWFVDztr1Ej8FVtYqP0r6+JFMapnzhzxg19ehXfCBFGDlZoqAk9Bgahl+sc/RK3D3TNnE9mL3FxR9ZGUJGr7PD3FHzTOzuIxdizQp484t04PJ6TqcBRYXSYP/9TtQ2GqUm2HwNzb1pvbKL3QE40BeDvkIyysBhf46SfN7i70hkdKFefW0ooV2v2XXqrm5P/7P9Hk4uIiwkRmpmjuqomAANGxeufOys+Rm8JWrxbnzpkjgs6JE6JvUrt2opZw8mTRLAeI2qqmTUXguftvFlN/YOs2/bVrZ9prieojedb5QYO0x4xYRYDsGwOQtZkjABUXa3ZtEYD8HPNr1kKhk8Z/xT/Q9ozZiqbn7beBr78W+z/8IFpfqiWPsZU78+7erR1We+CAaOY5eFD8lbhpk2gSGjAA2LFDVJn36CFq5dzdtYHkzBnRZ6CyJT/uHkseGwuMH2/43C5dtPv8C5WIqNYYgKxN7kCrE2JMpvPa7Fsqqy2xcC3fE9EAvBT5NbtAoVgENfvxp1G81gVnzlhmeYi1a8U2Lk5bgWKy++7T7nfvLrYP3Blt17ev9rnhwyu/RqtWNXxzIiKyNPY0tDYz1gCVQYlyKJFb+6XFjHKpQKy75lOWVfmsfFW5E4C8gt3h4CC+NGaQkimysrStV8uXs7KEiIgMYwCyNjMGoBKFqE36y4jRnuZwKi8UAOBUXqwdvmuKOwFI6e2hGYl8+nTlp9fEm2+KQUWdO9fbmdyJiMgKGICszYwBqNxRBKDjx2tbKONcTFMhE3emLr961fQL3AlAcHfXtA6ZMjq1OuPHA0uWiP233mLtDxERVY4ByNrM2AdI7SSudelSbQtlnCtXgKtoLL6oZQCSu9GsW2eWoiE/H/jsM7EfECD6JxMREVWGAcjazFgDJDmLAJSRUdXJ5nH+vOhbY64A9NBDYvfgwZp1J7rb3r3a/fXrWftDRERVYwCyNjMGIMWd2iRzdyQ2ZP58sTVXAGrZUkzlXlAgZkyvrR9+ENunntIfwEVERGQIA5C1mTMAuVovAMl9ns0VgJydtetwyss61dRXXwEficXB8eijtbsWERE1DAxA1mbGPkBKN3Gty5fFyCdLkq/fb/SdoVVXrph2gdxcsdAlIGYzhljPExBLT9XGBx+IrYMD0L9/7a5FREQNAwOQtZmxBsjFWwVfX1E7U9sQUR25BsihiRgKb3K71e7dogaoWTPNxIJDh4qnPv1UrHhcE+++K/oRAWKZH66hSURExuCvC2szYwBSuqo0C36mWHBdLUAbgFzD7iwZcfOm8S++dQt48EGx37atJqX8859iCazsbGD/ftPLlJ4OTJum/Zp9f4iIyFgMQNYmByBzLIWhUiHgzrQ816/XrljVkQOQe1PRfGVSAHr/fe2+vOYWACcnoGtXsX/+vOllOqOzlthzzwGOXNiFiIiMxABkbXIfIHMshqpSafKEJQOQJGnzjneEn9i5dcv4z3DkiHZfqdR7Su4Ife6c6eU6e1ZsfX21EyASEREZgwHI2szRBFZUJLaurpoaoKys2hWrKnl52k7QvuFe2hBjbC2QPPrr7n0ALVuKrakjwa5cAZ58UuwPH855f4iIyDQMQNZmjgB065bYurtbpQZI0//HFXB1UwB+fvpPVCcnR7vv5aX31L33iu3evaaNZJs0Sbvfs6fxryMiIgIYgKzPHH2A5ADk5obAQLFrjskEKyPnnDuj12sXgObO1XuqUyfA21vUMiUnG3e5rCztxIcAl70gIiLTMQBZmzn6AOlMKNi+vdg9c0ash2UJFQJQ6J2h8NVNhpiXByxapG3fOnKkwhLtSqV29NbOncaV5+OPxTY8XMyBJDcDEhERGYsByNrM2QTm5oagIJEpJMn4GhRTLVwoth4edw40bSq21a3C2rs38MIL2q99fAye1qeP2L7wAvDjj1Vf8uRJYNYssT9vnhhGT0REZCoGIGszRwDSqQECoFcLZAlJSWLr7HznQHi42FYXgI4d0/+6mgAEAEOGAD/9VPkl779fu9+7d9VvT0REVBkGIGszx1IYOjVAgHYoeU3m0qmObsfkmTPv7Mg1QKmplb9QLqOuuzpAy7p2Be65R/v1Qw8Bv/9e8Ty1GsjM1H4t5zAiIiJTMQBZmzlrgKwQgOTh9Q4OwD/+ceegMbMv6o7L9/QE1q+vMAeQzNEROHBAp4kNwJ49Fc9bvVq7P3Mmh74TEVHNce5cazPzMHjAsgEoI0NsAwJ08ovcG7qqUWC6ASgzU/u5q7BxI9C3r9g/elT/ubw8YORIsd+4MfDmm9VejoiIqFKsAbI2M3eCBiwbgORuPEFBOgeNCUByYbp0MSr8AKIv0M8/i/21a7UVXbduAW+8oT1v0CCjLkdERFQp1gBZmzn6AN3VCVoOQFlZYii8p2ctyneXL78U206ddA7KASg3Fygrq7gIV0kJ8O9/i/127Ux6vy5dtPvjx4vaHnkUmkw3DBEREdUEA5C1ybUh8nIWNXFXDZCXl1hj9Pp1UfGiF1Zq4ddftSPAxo3TecLXV7vfuTPw55+aFd4BAE89pe2tbGJa0Z3T59tvKz6flaW3nioREVGNsAnM2u6EFpSUmLb2g667OkEDQIsWYisvEGoO/fpp9+XrA9Cv8fnrLyAtTft1Xh7w3Xdif/DgGg3Vqqopj+GHiIjMoU4EoKVLl6JZs2ZwcXFBTEwMDhw4UOm5K1asgEKh0Hu43NXHRJIkzJ49GyEhIXB1dUVcXBzOWGqSHFPphJYa1wLd1Qka0C4qas4ApCs4+K4DL76o3c/O1u4fOiT6N4WH669XYYKICP0RX02bihFf06bV6HJEREQV2DwArVmzBlOnTsWcOXNw5MgRdOrUCfHx8cjUnfDlLl5eXkhLS9M8Lt01Id+CBQvw/vvvY9myZdi/fz/c3d0RHx+P27XpeGwuumHN0Fw51Skv1/Yf0glTcgA6fboWZavC3d189IZhyQEoI0NbbRQdXatx6sOGiXl/1Gox3+K1axz5RURE5mPzALRo0SKMHz8eY8eORbt27bBs2TK4ublh+fLllb5GoVAgODhY8wjSGaIkSRKWLFmCV199FUOGDEHHjh3x5Zdf4tq1a9iwYYPB6xUXFyMvL0/vYTEODmJZdaBmAUj3NTo1QFFRYnv38PGaklvZACAx0cAJDg5A9+5iPztbJBTdVUl1ZzasIYVCm6GCgwEnp1pfkoiICICNA1BJSQkOHz6MuLg4zTEHBwfExcVh3759lb6uoKAA4eHhCAsLw5AhQ/DXX39pnrtw4QLS09P1runt7Y2YmJhKrzl//nx4e3trHmGWXmBKrrmpTQBSKPRqk+S8cfx47UbYy+RJnj09gRUrKjlJ7gydnQ3ExorO0LKnnqp9IYiIiCzEpgHo+vXrKC8v16vBAYCgoCCkp6cbfE1kZCSWL1+OH374AV9//TXUajV69OiBK1euAIDmdaZcc+bMmcjNzdU8Uqta4sEcahOAdDtA6zQxhYWJEVRlZRWX4KqOJFU8du6c2MpD7A2S33/MGLEsu+6L2VuZiIjqMJs3gZkqNjYWo0ePRufOndGnTx+sX78eAQEB+Pjjj2t8TZVKBS8vL72HRZmjBki3MzVEFpFrgaroQ67n2DFRw/PaaxWfkwOQ3uivu2lWR71LlamJiIjI9mwagPz9/aFUKpEhr7dwR0ZGBoIrDDsyzMnJCV26dMHZO8Of5NfV5poWZ64aoLv07Cm2lXR10sjLE4Gpc2egoEAEoF279M+RO1NXGYAMJaetW6t+cyIiojrApgHI2dkZ0dHRSJJn2wOgVquRlJSE2NhYo65RXl6O48ePIyQkBAAQERGB4OBgvWvm5eVh//79Rl/T4uTwUpNh8AaGwMuGDxfbHTuq7ge0dm3FY7qzLb/8MrB0qdjv3LmKsnTurF2gSxYfX8ULiIiI6gabN4FNnToVn376KVauXIm///4bEyZMQGFhIcaOHQsAGD16NGbOnKk5f968efjll19w/vx5HDlyBE888QQuXbqEp+50ulUoFJgyZQr+85//4Mcff8Tx48cxevRohIaGYujQobb4iBVZqAYoIkI0aanVlU8mWFAAvPRSxeM//STW4UpNBebP1x6Xa5Uq9fDD2v3Jk6s5mYiIqG6w+VIYw4YNQ1ZWFmbPno309HR07twZW7du1XRivnz5Mhx0llnIzs7G+PHjkZ6eDl9fX0RHR2Pv3r1op7Pm1IwZM1BYWIinn34aOTk5uO+++7B169YKEybajAX6AAGiWatVK+DIEeDMGcPLcG3bJtYwdXMTI8auXQN69RLPDRxY8fymTaspzz//CXzyCdC6tVjNlIiIqB6weQACgEmTJmHSpEkGn9uxY4fe14sXL8bixYurvJ5CocC8efMwb948cxXRvMxRA2SgCQwQOeTIEbFCxZAhFZ+Xb+eTT4q+ys2bA3PmGO7OExBgxFyGCoVYtZSIiKgesXkTWINkwQAUHS22hw4Zfvnx4/rnAcDcucCSJWJaoWefFWFo+HBg927Ti0dERFQf1IkaoAbHHE1glQSgmBixNTQU/swZ4LffxL48c7Rs8mR24SEiooaDNUC2YKFO0ADQtatYpeLqVfHQ9eyzYtuxo3gQERE1VAxAtlCbtcCqaQJzdwc6dBD7uk1YWVmAPDPA+vVcV4uIiBo2BiBbsGAfIEA7muuTT7TLXIwdK/Y7d65mckMiIqIGgAHIFizYBwgQI7ycnYFffwW+/170+9m0STyXkGD6WxIREdkbBiBbsGAfIACIjARmzBD7jzwCDBumfe5f/zL9LYmIiOwNA5AtWLgJDNAf0ZWVBSiVwM6d2v5BREREDRkDkC1YIQD5+wNff639etw4oHdv09+OiIjIHnEeIFuw0FIYdxs5EsjOBk6eBGbNMv2tiIiI7BUDkC3ItTf5+aa/1sgaIFklK4wQERE1aGwCs4XwcLFNTQVu3zbttSYGICIiIqqIAcgWgoMBHx9ArQZOnzbttSY0gREREZFhDEC2oFCIseoAcPasaa9lDRAREVGtMQDZio+P2BYUGP+a8nJtkxkDEBERUY0xANmKHGBMCUC6o8bYBEZERFRjDEC2IgcguUnLGLoBSF5QlYiIiEzGAGQrNQlAustgOPBbR0REVFP8LWortQ1AREREVGMMQLbi4SG2NQlA7ABNRERUKwxAtlKTTtDp6WIbGGj+8hARETUgDEC2UpMmsKtXxbZxY/OXh4iIqAFhALIVBiAiIiKbYQCyFbkPkClNYAxAREREZsEAZCteXmKbl2f8a7KyxDYoyPzlISIiakAYgGzF11dsc3KMf012tv5riYiIqEYYgGxFXgtMDjXGYAAiIiIyCwYgW9FdDLWszLjXMAARERGZBQOQrXh7a/dzc6s/X5IYgIiIiMyEAchWnJy0I8GM6QdUVASUlop9BiAiIqJaYQCyJVP6AcnnKJXa4EREREQ1wgBkS3IAMqYG6Pp1sfX3BxQKS5WIiIioQWAAsiVTAlBmptgGBFiqNERERA0GA5AtmTIXkDwJIgMQERFRrdWJALR06VI0a9YMLi4uiImJwYEDByo999NPP0WvXr3g6+sLX19fxMXFVTh/zJgxUCgUeo+BAwda+mOYriY1QFwJnoiIqNZsHoDWrFmDqVOnYs6cOThy5Ag6deqE+Ph4ZMq/8O+yY8cOjBgxAr/99hv27duHsLAwDBgwAFfldbLuGDhwINLS0jSPb7/91hofxzSmdIJmDRAREZHZ2DwALVq0COPHj8fYsWPRrl07LFu2DG5ubli+fLnB81etWoVnn30WnTt3Rps2bfDZZ59BrVYjKSlJ7zyVSoXg4GDNw7cuDh1nDRAREZFN2DQAlZSU4PDhw4iLi9Mcc3BwQFxcHPbt22fUNW7duoXS0lL4+fnpHd+xYwcCAwMRGRmJCRMm4MaNG5Veo7i4GHl5eXoPq5BDGWuAiIiIrMqmAej69esoLy9H0F2rmwcFBSE9Pd2oa7z44osIDQ3VC1EDBw7El19+iaSkJLz99tvYuXMnEhISUF5ebvAa8+fPh7e3t+YRFhZW8w9lCjnMZGRUf64cgFgDREREVGuOti5Abbz11ltYvXo1duzYARcXF83x4cOHa/ajoqLQsWNHtGjRAjt27EC/fv0qXGfmzJmYOnWq5uu8vDzrhKAmTcT2ypXqz+UweCIiIrOxaQ2Qv78/lEolMu6qAcnIyEBwcHCVr124cCHeeust/PLLL+jYsWOV5zZv3hz+/v44e/aswedVKhW8vLz0HlYhh6zUVLHWV1VYA0RERGQ2Ng1Azs7OiI6O1uvALHdojo2NrfR1CxYswOuvv46tW7eiW7du1b7PlStXcOPGDYSEhJil3GbTuLHYFhVpa3gMKS7WLpjKGiAiIqJas/kosKlTp+LTTz/FypUr8ffff2PChAkoLCzE2LFjAQCjR4/GzJkzNee//fbbmDVrFpYvX45mzZohPT0d6enpKCgoAAAUFBRg+vTp+OOPP3Dx4kUkJSVhyJAhaNmyJeLj423yGSvl4gK0by/2v/668vPkZTCUSu3IMSIiIqoxmwegYcOGYeHChZg9ezY6d+6M5ORkbN26VdMx+vLly0hLS9Oc/9FHH6GkpASPPvooQkJCNI+FCxcCAJRKJf7880889NBDaN26NcaNG4fo6Gj8/vvvUKlUNvmMVRoxQmyPHav8HN0RYA42/5YRERHVe3WiE/SkSZMwadIkg8/t2LFD7+uLFy9WeS1XV1f8/PPPZiqZFcgdoasaCcYO0ERERGbF6gRbk6cAqCoAsQM0ERGRWTEA2ZoxAYg1QERERGbFAGRrcgDKygJKSgyfc/my2MqjxoiIiKhWGIBsLTgYCAkBysuB//3P8Dny/EWtWlmvXERERHaMAcjWHByACRPE/gcfGD7nzBmxbdnSOmUiIiKycwxAdcHIkWJ76BCgVus/V14OnD8v9hmAiIiIzIIBqC6Ql8QoKwPuXrU+NRUoLQVUKu15REREVCsMQHWBkxPg6yv2V6zQf278eLFt1oyTIBIREZkJf6PWFdnZYjtjhv5xeYZoDoEnIiIyGwagusLDo+IxtVo7CeJ//2vd8hAREdkxBqC64rfftPsFBaLzc3Ky+NrBAWjXzibFIiIiskcMQHVFdDTg5ib2//oLWLBAHAPEXEFOTrYrGxERkZ2pE4uhEgCFQgSd8+eBe+/Vf87FxTZlIiIislOsAapLYmIMH3/nHeuWg4iIyM4xANUlX34JvPyy/rG1a4GHH7ZNeYiIiOwUA1Bd4ugIvPEGMHiw9lhCgu3KQ0REZKfYB6guWrNGhKCQEMPD44mIiKhWGIDqIldXYPt2W5eCiIjIbrEJjIiIiBocBiAiIiJqcBiAiIiIqMFhACIiIqIGhwGIiIiIGhwGICIiImpwGICIiIiowWEAIiIiogaHAYiIiIgaHAYgIiIianAYgIiIiKjBYQAiIiKiBocBiIiIiBocBiAiIiJqcBxtXYC6SJIkAEBeXp6NS0JERETGkn9vy7/Hq8IAZEB+fj4AICwszMYlISIiIlPl5+fD29u7ynMUkjExqYFRq9W4du0aPD09oVAozHrtvLw8hIWFITU1FV5eXma9NmnxPlsH77N18D5bD++1dVjqPkuShPz8fISGhsLBoepePqwBMsDBwQFNmjSx6Ht4eXnxP5cV8D5bB++zdfA+Ww/vtXVY4j5XV/MjYydoIiIianAYgIiIiKjBYQCyMpVKhTlz5kClUtm6KHaN99k6eJ+tg/fZenivraMu3Gd2giYiIqIGhzVARERE1OAwABEREVGDwwBEREREDQ4DEBERETU4DEBWtHTpUjRr1gwuLi6IiYnBgQMHbF2kemX+/Pm455574OnpicDAQAwdOhQpKSl659y+fRsTJ05Eo0aN4OHhgUceeQQZGRl651y+fBmDBg2Cm5sbAgMDMX36dJSVlVnzo9Qrb731FhQKBaZMmaI5xvtsHlevXsUTTzyBRo0awdXVFVFRUTh06JDmeUmSMHv2bISEhMDV1RVxcXE4c+aM3jVu3ryJkSNHwsvLCz4+Phg3bhwKCgqs/VHqrPLycsyaNQsRERFwdXVFixYt8Prrr+utFcX7XDO7du3C4MGDERoaCoVCgQ0bNug9b677+ueff6JXr15wcXFBWFgYFixYYJ4PIJFVrF69WnJ2dpaWL18u/fXXX9L48eMlHx8fKSMjw9ZFqzfi4+OlL774Qjpx4oSUnJwsPfDAA1LTpk2lgoICzTnPPPOMFBYWJiUlJUmHDh2S7r33XqlHjx6a58vKyqQOHTpIcXFx0tGjR6XNmzdL/v7+0syZM23xkeq8AwcOSM2aNZM6duwoTZ48WXOc97n2bt68KYWHh0tjxoyR9u/fL50/f176+eefpbNnz2rOeeuttyRvb29pw4YN0rFjx6SHHnpIioiIkIqKijTnDBw4UOrUqZP0xx9/SL///rvUsmVLacSIEbb4SHXSG2+8ITVq1EjauHGjdOHCBem7776TPDw8pPfee09zDu9zzWzevFl65ZVXpPXr10sApO+//17veXPc19zcXCkoKEgaOXKkdOLECenbb7+VXF1dpY8//rjW5WcAspLu3btLEydO1HxdXl4uhYaGSvPnz7dhqeq3zMxMCYC0c+dOSZIkKScnR3JycpK+++47zTl///23BEDat2+fJEniP6yDg4OUnp6uOeejjz6SvLy8pOLiYut+gDouPz9fatWqlbRt2zapT58+mgDE+2weL774onTfffdV+rxarZaCg4Old955R3MsJydHUqlU0rfffitJkiSdPHlSAiAdPHhQc86WLVskhUIhXb161XKFr0cGDRokPfnkk3rHHn74YWnkyJGSJPE+m8vdAchc9/XDDz+UfH199X5uvPjii1JkZGSty8wmMCsoKSnB4cOHERcXpznm4OCAuLg47Nu3z4Ylq99yc3MBAH5+fgCAw4cPo7S0VO8+t2nTBk2bNtXc53379iEqKgpBQUGac+Lj45GXl4e//vrLiqWv+yZOnIhBgwbp3U+A99lcfvzxR3Tr1g2PPfYYAgMD0aVLF3z66aea5y9cuID09HS9++zt7Y2YmBi9++zj44Nu3bppzomLi4ODgwP2799vvQ9Th/Xo0QNJSUk4ffo0AODYsWPYvXs3EhISAPA+W4q57uu+ffvQu3dvODs7a86Jj49HSkoKsrOza1VGLoZqBdevX0d5ebneLwMACAoKwqlTp2xUqvpNrVZjypQp6NmzJzp06AAASE9Ph7OzM3x8fPTODQoKQnp6uuYcQ98H+TkSVq9ejSNHjuDgwYMVnuN9No/z58/jo48+wtSpU/Hyyy/j4MGDeO655+Ds7IzExETNfTJ0H3Xvc2BgoN7zjo6O8PPz432+46WXXkJeXh7atGkDpVKJ8vJyvPHGGxg5ciQA8D5biLnua3p6OiIiIipcQ37O19e3xmVkAKJ6aeLEiThx4gR2795t66LYndTUVEyePBnbtm2Di4uLrYtjt9RqNbp164Y333wTANClSxecOHECy5YtQ2Jioo1LZz/Wrl2LVatW4ZtvvkH79u2RnJyMKVOmIDQ0lPe5gWMTmBX4+/tDqVRWGCWTkZGB4OBgG5Wq/po0aRI2btyI3377DU2aNNEcDw4ORklJCXJycvTO173PwcHBBr8P8nMkmrgyMzPRtWtXODo6wtHRETt37sT7778PR0dHBAUF8T6bQUhICNq1a6d3rG3btrh8+TIA7X2q6udGcHAwMjMz9Z4vKyvDzZs3eZ/vmD59Ol566SUMHz4cUVFRGDVqFJ5//nnMnz8fAO+zpZjrvlryZwkDkBU4OzsjOjoaSUlJmmNqtRpJSUmIjY21YcnqF0mSMGnSJHz//ff49ddfK1SLRkdHw8nJSe8+p6Sk4PLly5r7HBsbi+PHj+v9p9u2bRu8vLwq/DJqqPr164fjx48jOTlZ8+jWrRtGjhyp2ed9rr2ePXtWmMbh9OnTCA8PBwBEREQgODhY7z7n5eVh//79evc5JycHhw8f1pzz66+/Qq1WIyYmxgqfou67desWHBz0f9UplUqo1WoAvM+WYq77Ghsbi127dqG0tFRzzrZt2xAZGVmr5i8AHAZvLatXr5ZUKpW0YsUK6eTJk9LTTz8t+fj46I2SoapNmDBB8vb2lnbs2CGlpaVpHrdu3dKc88wzz0hNmzaVfv31V+nQoUNSbGysFBsbq3leHp49YMAAKTk5Wdq6dasUEBDA4dnV0B0FJkm8z+Zw4MABydHRUXrjjTekM2fOSKtWrZLc3Nykr7/+WnPOW2+9Jfn4+Eg//PCD9Oeff0pDhgwxOIy4S5cu0v79+6Xdu3dLrVq1avDDs3UlJiZKjRs31gyDX79+veTv7y/NmDFDcw7vc83k5+dLR48elY4ePSoBkBYtWiQdPXpUunTpkiRJ5rmvOTk5UlBQkDRq1CjpxIkT0urVqyU3NzcOg69vPvjgA6lp06aSs7Oz1L17d+mPP/6wdZHqFQAGH1988YXmnKKiIunZZ5+VfH19JTc3N+mf//ynlJaWpnedixcvSgkJCZKrq6vk7+8vvfDCC1JpaamVP039cncA4n02j59++knq0KGDpFKppDZt2kiffPKJ3vNqtVqaNWuWFBQUJKlUKqlfv35SSkqK3jk3btyQRowYIXl4eEheXl7S2LFjpfz8fGt+jDotLy9Pmjx5stS0aVPJxcVFat68ufTKK6/oDavmfa6Z3377zeDP5MTEREmSzHdfjx07Jt13332SSqWSGjduLL311ltmKb9CknSmwyQiIiJqANgHiIiIiBocBiAiIiJqcBiAiIiIqMFhACIiIqIGhwGIiIiIGhwGICIiImpwGICIiIiowWEAIiIiogaHAYiIqBJ9+/bFlClTbF0MIrIAzgRNRFSJmzdvwsnJCZ6enrYuChGZGQMQERERNThsAiOiOi8rKwvBwcF48803Ncf27t0LZ2dnJCUlGXzNwYMH0b9/f/j7+8Pb2xt9+vTBkSNHNM/v2LEDzs7O+P333zXHFixYgMDAQGRkZACo2AT24YcfolWrVnBxcUFQUBAeffRRM39SIrIWBiAiqvMCAgKwfPlyzJ07F4cOHUJ+fj5GjRqFSZMmoV+/fgZfk5+fj8TEROzevRt//PEHWrVqhQceeAD5+fkAtOFm1KhRyM3NxdGjRzFr1ix89tlnCAoKqnC9Q4cO4bnnnsO8efOQkpKCrVu3onfv3hb93ERkOWwCI6J6Y+LEidi+fTu6deuG48eP4+DBg1CpVEa9Vq1Ww8fHB9988w0efPBBAEBJSQliYmLQunVrnDhxAj179sQnn3yieU3fvn3RuXNnLFmyBOvXr8fYsWNx5coV9gkisgOsASKiemPhwoUoKyvDd999h1WrVkGlUuHy5cvw8PDQPORmsoyMDIwfPx6tWrWCt7c3vLy8UFBQgMuXL2uu5+zsjFWrVmHdunW4ffs2Fi9eXOl79+/fH+Hh4WjevDlGjRqFVatW4datWxb/zERkGY62LgARkbHOnTuHa9euQa1W4+LFi4iKikJoaCiSk5M15/j5+QEAEhMTcePGDbz33nsIDw+HSqVCbGwsSkpK9K65d+9eAGLE182bN+Hu7m7wvT09PXHkyBHs2LEDv/zyC2bPno25c+fi4MGD8PHxscjnJSLLYRMYEdULJSUl6N69Ozp37ozIyEgsWbIEx48fR2BgoMHzPT098eGHH2LUqFEAgNTUVDRt2hSLFy/WdGw+d+4cOnfujPfffx9r1qxBSUkJtm/fDgcHUTmu2wR2t8LCQvj4+GDNmjV4+OGHLfKZichyWANERPXCK6+8gtzcXLz//vvw8PDA5s2b8eSTT2Ljxo0Gz2/VqhW++uordOvWDXl5eZg+fTpcXV01z5eXl+OJJ55AfHw8xo4di4EDByIqKgrvvvsupk+fXuF6GzduxPnz59G7d2/4+vpi8+bNUKvViIyMtNhnJiLLYR8gIqrzduzYgSVLluCrr76Cl5cXHBwc8NVXX+H333/HRx99ZPA1n3/+ObKzs9G1a1eMGjUKzz33nF5t0RtvvIFLly7h448/BgCEhITgk08+wauvvopjx45VuJ6Pjw/Wr1+Pf/zjH2jbti2WLVuGb7/9Fu3bt7fMhyYii2ITGBERETU4rAEiIiKiBocBiIiIiBocBiAiIiJqcBiAiIiIqMFhACIiIqIGhwGIiIiIGhwGICIiImpwGICIiIiowWEAIiIiogaHAYiIiIgaHAYgIiIianD+H8hKl0Bc0dlPAAAAAElFTkSuQmCC",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(dl, label='discriminator loss', color='blue', linestyle='-')\n",
    "plt.plot(gl, label='generator loss', color='red', linestyle='-')\n",
    "\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) GENERATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(generator, data_class, num_instances):\n",
    "    one_hot_class = one_hot_encoder.transform(np.array([[data_class]]))\n",
    "    noise = np.random.normal(0, 1, (num_instances, NOISE_DIM))\n",
    "    generated_data = generator.predict([noise, np.repeat(one_hot_class, num_instances, axis=0)])\n",
    "    return pd.DataFrame(generated_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1) plus encode in reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6250/6250 [==============================] - 32s 5ms/step\n",
      "5625/5625 [==============================] - 28s 5ms/step\n",
      "6250/6250 [==============================] - 37s 6ms/step\n",
      "6250/6250 [==============================] - 33s 5ms/step\n",
      "5000/5000 [==============================] - 25s 5ms/step\n",
      "6250/6250 [==============================] - 29s 5ms/step\n"
     ]
    }
   ],
   "source": [
    "# Generate 50 instances for each class\n",
    "synthetic_data_class_0 = generate_data(generator, 0, 200000)\n",
    "synthetic_data_class_1 = generate_data(generator, 1, 180000)\n",
    "synthetic_data_class_2 = generate_data(generator, 2, 200000)\n",
    "synthetic_data_class_3 = generate_data(generator, 3, 200000)\n",
    "synthetic_data_class_4 = generate_data(generator, 4, 160000)\n",
    "synthetic_data_class_5 = generate_data(generator, 5, 200000)\n",
    "\n",
    "# Combine all synthetic data into a single DataFrame and apply inverse transform to bring it back to original scale\n",
    "synthetic_data = pd.concat(\n",
    "    [\n",
    "        synthetic_data_class_0,\n",
    "        synthetic_data_class_1,\n",
    "        synthetic_data_class_2,\n",
    "        synthetic_data_class_3,\n",
    "        synthetic_data_class_4,\n",
    "        synthetic_data_class_5,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "COLUMNS = [\"Year\", \"Month\", \"Consumption\", \"Consumer_number\", \"Installation_zone\"]\n",
    "\n",
    "generated_data_clipped = np.clip(synthetic_data, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(\n",
    "    scaler.inverse_transform(generated_data_clipped),\n",
    "    columns=COLUMNS,\n",
    ")\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_labels = [0] * 200000 + [1] * 180000 + [2] * 200000 + [3] * 200000 + [4] * 160000 + [5] * 200000\n",
    "labels = pd.DataFrame(columns=[\"Consumer_type\"])\n",
    "labels[\"Consumer_type\"] = synthetic_labels\n",
    "\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "synthetic_label = enc_label.inverse_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) UNIFY TRAIN DATASET + SYTNEHTIC DATA GENERATED AND PLOT THE NEW SITUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(synthetic_data, columns=COLUMNS)\n",
    "df['Consumer_type'] = [item[0] for item in synthetic_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_without_outliers.csv\")\n",
    "result = pd.concat([train, df], axis=0)\n",
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1170x827 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "unb = pd.DataFrame({'Count' : result.groupby( [\"Consumer_type\"] ).size()}).reset_index()\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 11.7,8.27\n",
    "sns.barplot(data=unb, x=unb[\"Consumer_type\"], y=unb[\"Count\"])\n",
    "\n",
    "result.to_csv('train_with_synthetic_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
