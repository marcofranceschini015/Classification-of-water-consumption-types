{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1) IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###########################\n",
    "# data libraries\n",
    "###########################\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "###########################\n",
    "# plot libraries\n",
    "###########################\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib as mpl\n",
    "from matplotlib import rcParams\n",
    "\n",
    "\n",
    "###########################\n",
    "# data generation\n",
    "###########################\n",
    "from sklearn.preprocessing import OrdinalEncoder, OneHotEncoder, MinMaxScaler\n",
    "from tensorflow.keras.layers import Input, Dense, Concatenate\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2) READ DATA AND ENCODE/SCALE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Read data\n",
    "train = pd.read_csv(\"train_without_outliers.csv\")\n",
    "\n",
    "train = train[train['Consumer_type'] != 'domestic']\n",
    "y = train[['Consumer_type']]\n",
    "compare_label = y\n",
    "X = train[['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone']]\n",
    "\n",
    "## Encode data\n",
    "enc = OrdinalEncoder(dtype=np.int16)\n",
    "enc.fit(X)\n",
    "\n",
    "enc_label = OrdinalEncoder(dtype=np.int16)\n",
    "X[['Year', 'Month','Consumption' ,'Consumer_number', 'Installation_zone']]= enc.transform(X[['Year', 'Month','Consumption','Consumer_number', 'Installation_zone']])\n",
    "y[['Consumer_type']] = enc_label.fit_transform(y[['Consumer_type']])\n",
    "y = y.Consumer_type\n",
    "\n",
    "## Scale data\n",
    "scaler = MinMaxScaler()\n",
    "X = scaler.fit_transform(X)\n",
    "\n",
    "## Create data and label\n",
    "data = pd.DataFrame(X, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])\n",
    "label = y.values\n",
    "\n",
    "# One hot encode labels\n",
    "one_hot_encoder = OneHotEncoder(sparse=False)\n",
    "one_hot_labels = one_hot_encoder.fit_transform(np.array(label).reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3) GENERATOR AND DISCRIMINATOR + HYPERPARAMETERS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "NOISE_DIM = 100\n",
    "NUM_CLASSES = 6\n",
    "NUM_FEATURES = 5\n",
    "BATCH_SIZE = 64\n",
    "TRAINING_STEPS = 3000\n",
    "\n",
    "# Generator\n",
    "def create_generator():\n",
    "    noise_input = Input(shape=(NOISE_DIM,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    merged_input = Concatenate()([noise_input, class_input])\n",
    "    hidden = Dense(128, activation='relu')(merged_input)\n",
    "    output = Dense(NUM_FEATURES, activation='linear')(hidden)\n",
    "    model = Model(inputs=[noise_input, class_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# Discriminator\n",
    "def create_discriminator():\n",
    "    data_input = Input(shape=(NUM_FEATURES,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    merged_input = Concatenate()([data_input, class_input])\n",
    "    hidden = Dense(128, activation='relu')(merged_input)\n",
    "    output = Dense(1, activation='sigmoid')(hidden)\n",
    "    model = Model(inputs=[data_input, class_input], outputs=output)\n",
    "    return model\n",
    "\n",
    "# cGAN\n",
    "def create_cgan(generator, discriminator):\n",
    "    noise_input = Input(shape=(NOISE_DIM,))\n",
    "    class_input = Input(shape=(NUM_CLASSES,))\n",
    "    generated_data = generator([noise_input, class_input])\n",
    "    validity = discriminator([generated_data, class_input])\n",
    "    model = Model(inputs=[noise_input, class_input], outputs=validity)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create and compile the Discriminator\n",
    "discriminator = create_discriminator()\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=Adam())\n",
    "\n",
    "# Create the Generator\n",
    "generator = create_generator()\n",
    "\n",
    "# Create the GAN\n",
    "gan = create_cgan(generator, discriminator)\n",
    "\n",
    "# Ensure that only the generator is trained\n",
    "discriminator.trainable = False\n",
    "\n",
    "gan.compile(loss='binary_crossentropy', optimizer=Adam())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4) TRAINING OF THE GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train GAN\n",
    "dl = []\n",
    "gl = []\n",
    "for step in range(TRAINING_STEPS):\n",
    "    # Select a random batch of real data with labels\n",
    "    idx = np.random.randint(0, data.shape[0], BATCH_SIZE)\n",
    "    real_batch = data.iloc[idx].values\n",
    "    labels_batch = one_hot_labels[idx]\n",
    "\n",
    "    # Generate a batch of new data\n",
    "    noise = np.random.normal(0, 1, (BATCH_SIZE, NOISE_DIM))\n",
    "    generated_batch = generator.predict([noise, labels_batch])\n",
    "\n",
    "    # Train the discriminator\n",
    "    real_loss = discriminator.train_on_batch([real_batch, labels_batch], np.ones((BATCH_SIZE, 1)))\n",
    "    fake_loss = discriminator.train_on_batch([generated_batch, labels_batch], np.zeros((BATCH_SIZE, 1)))\n",
    "    discriminator_loss = 0.5 * np.add(real_loss, fake_loss)\n",
    "\n",
    "    # Train the generator\n",
    "    generator_loss = gan.train_on_batch([noise, labels_batch], np.ones((BATCH_SIZE, 1)))\n",
    "    dl.append(discriminator_loss)\n",
    "    gl.append(generator_loss)\n",
    "    if step % 2 == 0:\n",
    "        print(f\"Step: {step}, Discriminator Loss: {discriminator_loss}, Generator Loss: {generator_loss}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4.1) plot of the loss of the GAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.figure()\n",
    "plt.plot(dl, label='discriminator loss', color='blue', linestyle='-')\n",
    "plt.plot(gl, label='generator loss', color='red', linestyle='-')\n",
    "\n",
    "plt.xlabel('x-axis')\n",
    "plt.ylabel('y-axis')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) GENERATE DATA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_data(generator, data_class, num_instances):\n",
    "    one_hot_class = one_hot_encoder.transform(np.array([[data_class]]))\n",
    "    noise = np.random.normal(0, 1, (num_instances, NOISE_DIM))\n",
    "    generated_data = generator.predict([noise, np.repeat(one_hot_class, num_instances, axis=0)])\n",
    "    return pd.DataFrame(generated_data, columns=['Year', 'Month', 'Consumption', 'Consumer_number', 'Installation_zone'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5.1) plus encode in reverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate 50 instances for each class\n",
    "synthetic_data_class_0 = generate_data(generator, 0, 200000)\n",
    "synthetic_data_class_1 = generate_data(generator, 1, 180000)\n",
    "synthetic_data_class_2 = generate_data(generator, 2, 200000)\n",
    "synthetic_data_class_3 = generate_data(generator, 3, 200000)\n",
    "synthetic_data_class_4 = generate_data(generator, 4, 160000)\n",
    "synthetic_data_class_5 = generate_data(generator, 5, 200000)\n",
    "\n",
    "# Combine all synthetic data into a single DataFrame and apply inverse transform to bring it back to original scale\n",
    "synthetic_data = pd.concat(\n",
    "    [\n",
    "        synthetic_data_class_0,\n",
    "        synthetic_data_class_1,\n",
    "        synthetic_data_class_2,\n",
    "        synthetic_data_class_3,\n",
    "        synthetic_data_class_4,\n",
    "        synthetic_data_class_5,\n",
    "    ],\n",
    "    ignore_index=True,\n",
    ")\n",
    "\n",
    "COLUMNS = [\"Year\", \"Month\", \"Consumption\", \"Consumer_number\", \"Installation_zone\"]\n",
    "\n",
    "generated_data_clipped = np.clip(synthetic_data, 0, 1)\n",
    "synthetic_data_scaled = pd.DataFrame(\n",
    "    scaler.inverse_transform(generated_data_clipped),\n",
    "    columns=COLUMNS,\n",
    ")\n",
    "synthetic_data = synthetic_data_scaled.round().astype(np.int16)\n",
    "synthetic_labels = [0] * 200000 + [1] * 180000 + [2] * 200000 + [3] * 200000 + [4] * 160000 + [5] * 200000\n",
    "labels = pd.DataFrame(columns=[\"Consumer_type\"])\n",
    "labels[\"Consumer_type\"] = synthetic_labels\n",
    "\n",
    "synthetic_data = enc.inverse_transform(synthetic_data)\n",
    "synthetic_label = enc_label.inverse_transform(labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6) UNIFY TRAIN DATASET + SYTNEHTIC DATA GENERATED AND PLOT THE NEW SITUATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame(synthetic_data, columns=COLUMNS)\n",
    "df['Consumer_type'] = [item[0] for item in synthetic_label]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(\"train_without_outliers.csv\")\n",
    "result = pd.concat([train, df], axis=0)\n",
    "result.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unb = pd.DataFrame({'Count' : result.groupby( [\"Consumer_type\"] ).size()}).reset_index()\n",
    "# figure size in inches\n",
    "rcParams['figure.figsize'] = 11.7,8.27\n",
    "sns.barplot(data=unb, x=unb[\"Consumer_type\"], y=unb[\"Count\"])\n",
    "\n",
    "result.to_csv('train_with_synthetic_data.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
